# Release Notes

## v0.2.0: Personas Dataset Creation

**Release Date:** November 12, 2025  
**Milestone:** Unified Individual Records Extraction Complete

### ğŸ¯ Overview

This release marks the successful completion of the personas dataset creation phase. We have systematically extracted and consolidated all individuals mentioned across the three cleaned historical datasets (baptisms, marriages, and burials) into a unified `personas.csv` dataset, ready for probabilistic record linkage and entity resolution.

### ğŸ“Š Personas Dataset Summary

**Output:** `data/clean/personas.csv`
- Consolidated individual records from all three event types
- Role-based extraction preserving context (baptized, parent, godparent, spouse, deceased, etc.)
- Unified schema harmonizing fields across different record types
- Source record metadata maintained for traceability
- Standardized name and place fields ready for matching algorithms

### âœ¨ Key Achievements

#### 1. Individual Extraction
- âœ… Systematically extracted all persons from baptism records (children, parents, godparents)
- âœ… Extracted all persons from marriage records (spouses, witnesses, parents)
- âœ… Extracted all persons from burial records (deceased, parents, spouses)
- âœ… Preserved individual roles and relationships in the extraction process

#### 2. Schema Unification
- âœ… Created unified field structure across all record types
- âœ… Standardized column naming conventions for personas dataset
- âœ… Harmonized geographic and temporal fields
- âœ… Maintained data type consistency across extracted records

#### 3. Metadata Preservation
- âœ… Source record type tracking (baptism/marriage/burial)
- âœ… Source record ID references for traceability
- âœ… Event date preservation from original records
- âœ… Role context maintained for each individual

#### 4. Data Quality
- âœ… Validated extracted records against source data
- âœ… Applied existing normalization standards (names, places, dates)
- âœ… Documented extraction statistics and coverage metrics
- âœ… Quality assurance checks for data integrity

### ğŸ”§ Technical Implementation

#### Core Components Developed
- **PersonasExtractor**: Orchestrates extraction from all record types
- **RoleMapper**: Maps individuals to their contextual roles
- **SchemaUnifier**: Harmonizes fields across different sources
- **MetadataPreserver**: Maintains source record references

#### Extraction Pipeline
```
Cleaned Data â†’ Individual Identification â†’ Role Assignment â†’ 
Schema Unification â†’ Metadata Attachment â†’ Quality Validation â†’ 
Personas Dataset Export
```

### ğŸ“ File Structure
```
data/
â”œâ”€â”€ raw/           # Original datasets
â”œâ”€â”€ clean/         # Processed datasets
â”‚   â”œâ”€â”€ bautismos_clean.csv     âœ…
â”‚   â”œâ”€â”€ matrimonios_clean.csv   âœ…
â”‚   â”œâ”€â”€ entierros_clean.csv     âœ…
â”‚   â””â”€â”€ personas.csv            âœ… NEW
â”œâ”€â”€ interim/       # Intermediate processing files
â””â”€â”€ mappings/      # Configuration files

project_code/
â”œâ”€â”€ dataCleaning.ipynb         âœ…
â”œâ”€â”€ personasCreation.ipynb     âœ… NEW
â”œâ”€â”€ utils/                     # Core utility classes
â””â”€â”€ actions/                   # Processing modules
```

### ğŸ“ˆ Dataset Statistics

**Source Records Processed:**
- Baptisms: 6,340 records
- Marriages: 1,719 records
- Burials: 2,121 records
- **Total: 10,180 cleaned historical records**

**Personas Extracted:**
- Comprehensive extraction from all event types
- Multiple roles per individual preserved
- Ready for entity resolution and matching

### ğŸ¯ Next Phase: Probabilistic Record Linkage

With the personas dataset complete, the project advances to:

1. **Blocking Strategy**: Define blocking keys for efficient matching
2. **Similarity Scoring**: Implement probabilistic matching algorithms
3. **Entity Resolution**: Link duplicate individuals across records
4. **Unique ID Assignment**: Create consolidated individual identifiers
5. **Relationship Network**: Build familial and social connection graphs

### ğŸ› ï¸ Dependencies
- pandas (data manipulation)
- numpy (numerical operations)
- pathlib (file handling)
- Custom utilities from v0.1.0 (maintained)

### ğŸ“ Files Added/Modified
- **NEW:** `project_code/personasCreation.ipynb` - Personas extraction pipeline
- **NEW:** `data/clean/personas.csv` - Consolidated individual records
- **UPDATED:** `README.md` - Project status and phase documentation
- **UPDATED:** `RELEASE_NOTES.md` - This release documentation

### ğŸ”„ Design Decision: Database-Free Approach

This release adopts a streamlined approach, leveraging CSV-based processing instead of a relational database. This decision:
- âœ… Simplifies the workflow for probabilistic record linkage
- âœ… Reduces infrastructure complexity
- âœ… Maintains data portability and accessibility
- âœ… Enables efficient pandas-based processing pipelines

The personas dataset structure provides sufficient organization for subsequent matching and analysis phases without requiring database overhead.

---

## v0.1.0: Data Cleaning Milestone

**Release Date:** July 29, 2025  
**Pre-milestone Release:** Data Cleaning and Standardization Complete

### ğŸ¯ Overview

This release marks the completion of the comprehensive data cleaning and standardization phase for the Sondondo Valley Parish Records project. We have successfully processed and cleaned three historical datasets (baptisms, marriages, and burials) spanning 1760-1921, preparing them for the next phase of individual record creation and transformation.

### ğŸ“Š Dataset Summary

#### Cleaned Datasets
- **Baptisms (`bautismos_clean.csv`)**: 6,341 records
- **Marriages (`matrimonios_clean.csv`)**: 1,719 records  
- **Burials (`entierros_clean.csv`)**: 2,198 records
- **Total**: 10,258 cleaned historical records

### âœ¨ Key Achievements

#### 1. Column Harmonization
- âœ… Standardized column names across all three datasets using mapping files
- âœ… Applied consistent naming conventions for cross-dataset compatibility
- âœ… Reduced datasets to essential columns using `usefulColumnsMapping.json`
- âœ… Removed empty columns to optimize data structure

#### 2. Data Quality Improvements
- âœ… **Null Value Standardization**: Replaced inconsistent empty values (`''`, `'-'`, `'--'`, `'n/a'`, `'na'`, `'null'`, `'None'`) with proper `np.nan`
- âœ… **Date Normalization**: Standardized all dates to `YYYY-MM-DD` format using `DateNormalizer`
- âœ… **Age Inference**: Processed age-related fields and birthdates using `AgeInferrer`
- âœ… **Names Standardization**: Normalized all name fields using `NamesNormalizer`

#### 3. Advanced Data Processing
- âœ… **Place Recognition**: Implemented NER (Named Entity Recognition) for geographic location extraction from text fields
- âœ… **Geographic Standardization**: Processed place names in all location-related columns
- âœ… **Relationship Data**: Preserved and cleaned family relationship information (parents, godparents, witnesses)

#### 4. Quality Assurance
- âœ… **Data Validation**: Identified and documented inconsistent date records (birthdates after event dates)
- âœ… **Cleaning Audit**: Comprehensive audit system tracking missing values and data quality metrics
- âœ… **Documentation**: Complete process documentation in Jupyter notebook format

### ğŸ”§ Technical Implementation

#### Core Components Developed
- **ColumnManager**: Handles column harmonization and mapping
- **DateNormalizer**: Standardizes date formats across datasets
- **AgeInferrer**: Processes and infers age-related information
- **NamesNormalizer**: Standardizes personal names
- **PlaceExtractor**: Extracts and normalizes geographic entities

#### Data Processing Pipeline
```
Raw Data â†’ Column Harmonization â†’ Null Value Cleanup â†’ 
Date Normalization â†’ Age Processing â†’ Name Standardization â†’ 
Place Recognition â†’ Quality Audit â†’ Clean Data Export
```

### ğŸ“ File Structure
```
data/
â”œâ”€â”€ raw/           # Original datasets
â”œâ”€â”€ clean/         # Processed, standardized datasets âœ…
â”œâ”€â”€ interim/       # Intermediate processing files
â””â”€â”€ mappings/      # Column and value mapping configurations

project_code/
â”œâ”€â”€ dataCleaning.ipynb    # Complete data cleaning pipeline âœ…
â”œâ”€â”€ utils/               # Core utility classes
â””â”€â”€ actions/            # Processing modules
    â”œâ”€â”€ normalizers/    # Data normalization tools
    â”œâ”€â”€ generators/     # Data generation utilities
    â””â”€â”€ extractors/     # Entity extraction tools
```

### ğŸš¨ Known Issues
- **Date Inconsistencies**: Some records contain birthdates after event dates, requiring manual verification against original sources
- **Missing Data**: Certain fields have high missing value percentages, documented in audit reports

### ğŸ“ˆ Data Quality Metrics
- **Missing Values**: Comprehensive tracking and reporting implemented
- **Standardization**: 100% of name and place fields processed through normalization
- **Date Validation**: All date fields converted to standard format with error flagging
- **Audit Trail**: Complete documentation of all cleaning operations

### ğŸ› ï¸ Dependencies
- pandas (data manipulation)
- numpy (numerical operations)  
- pathlib (file handling)
- Custom utilities (ColumnManager, DateNormalizer, etc.)

### ğŸ“ Files Modified/Added
- `project_code/dataCleaning.ipynb` - Complete data cleaning pipeline
- `data/clean/*.csv` - Cleaned datasets ready for next phase
- `project_code/utils/` - Core utility modules
- `project_code/actions/` - Data processing modules

### ğŸ”„ Migration Notes
- All future processing should use files from `data/clean/` directory
- Original raw data preserved in `data/raw/` for reference
- Mapping configurations available in `data/mappings/` for reference

---