[
  {
    "objectID": "5_visualizations.html",
    "href": "5_visualizations.html",
    "title": "Sondondo Project Notebooks",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n\nbautismos_path = \"../data/clean/bautismos_clean.csv\"\nentierros_path = \"../data/clean/entierros_clean.csv\"\nmatrimonios_path = \"../data/clean/matrimonios_clean.csv\"\n\nbautismos = pd.read_csv(bautismos_path)\nentierros = pd.read_csv(entierros_path)\nmatrimonios = pd.read_csv(matrimonios_path)\n\n\nos.makedirs(\"../figures\", exist_ok=True)\n\n\ndef prepare_events(df, sacrament_label):\n    df = df.copy()\n    df[\"event_date\"] = pd.to_datetime(df[\"event_date\"], errors=\"coerce\")\n    df = df.dropna(subset=[\"event_date\"])\n    df[\"year\"] = df[\"event_date\"].dt.year\n    df[\"sacrament\"] = sacrament_label\n    return df[[\"year\", \"sacrament\"]]\n\nbautismos_yearly = prepare_events(bautismos, \"Baptisms\")\nentierros_yearly = prepare_events(entierros, \"Burials\")\nmatrimonios_yearly = prepare_events(matrimonios, \"Marriages\")\n\n\nevents_all = pd.concat(\n    [bautismos_yearly, entierros_yearly, matrimonios_yearly],\n    ignore_index=True\n)\n\nyearly_counts = (\n    events_all\n    .groupby([\"year\", \"sacrament\"])\n    .size()\n    .reset_index(name=\"count\")\n)\n\nyearly_pivot = yearly_counts.pivot(index=\"year\", columns=\"sacrament\", values=\"count\")\n\nyearly_pivot = yearly_pivot.fillna(0).sort_index()\n\n\nyears = yearly_pivot.index.values\ncols  = yearly_pivot.columns\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(len(years))  \n\nfor sacrament in cols:\n    counts = yearly_pivot[sacrament].values\n    ax.bar(\n        years,\n        counts,\n        bottom=bottom,\n        label=sacrament\n    )\n    bottom += counts  \n\nax.set_xlabel(\"Year\")\nax.set_ylabel(\"Number of events\")\nax.legend(title=\"Event Type\")\n\nplt.tight_layout()\nplt.show()\n\nfig.savefig(\"../figures/distribution_events_per_year.png\", dpi=300)",
    "crumbs": [
      "Notebooks",
      "Visualizations"
    ]
  },
  {
    "objectID": "3_termExtraction.html",
    "href": "3_termExtraction.html",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "",
    "text": "This analysis builds upon ealier iterations using textAnalysis.py and textualAnalysis.py which led to the creation of the current conditionMapping.json.\nThe goal of this analysis is to examine textual variation and overlapping categories within the “conditions” columns across the cleaned datasets (data/clean/bautismos_clean.csv, data/clean/matrimonios_clean.csv, and data/clean/defunciones_clean.csv). This helps to evaluate how a reduced and harmonized mapping contributes to a more consistent and maneageable classification scheme.",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "3_termExtraction.html#strategy-for-creating-conditionmapping.json",
    "href": "3_termExtraction.html#strategy-for-creating-conditionmapping.json",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "Strategy for Creating conditionMapping.json",
    "text": "Strategy for Creating conditionMapping.json\nThe main objective was to reduce textual variation in the “conditions” columns without inadvertently losing important information. The process involved the following steps:\n\nDefine three main categories of “conditions”:\n\nLegitimacy status: Wheter the child was born within a legitimate marriage.\nMarital status: Wheter a persona was married, divorced, or widowed at the time of the event.\nSocial condition: Labels used by the authority recording the event to mark social origin or perceived status (e.g., “indigena”, “mestizo”).\n\nRun TF-IDF analysis across all “conditions” columns from the raw datasets to identify the most frequent and distinctive keywords in each group.\n\nResults can be found in main@e3d7781/logs/textanalysis.log\n\nManually curate mapping from the top-ranked terms for each category. The following criteria guided the normalization process:\n\nRemove diacritics and accents.\nConvert all gendered terms to their masculine form.\nUse singular rather than plural forms.\nExpand abbreviations to full terms.\nConsolidate synonyms into the most commonly used or historically accurate term, e.g., “natural” mapped to “indio”.",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "3_termExtraction.html#set-the-project",
    "href": "3_termExtraction.html#set-the-project",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "Set the Project",
    "text": "Set the Project\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport json\n\nfrom utils.LoggerHandler import setup_logger\n\nlogger = setup_logger(\"termExtraction\")\n\n\ndataframes_paths = {\n    \"bautismos\": {\n        \"csv_file\": \"../data/clean/bautismos_clean.csv\"\n    },\n    \"entierros\": {\n        \"csv_file\": \"../data/clean/entierros_clean.csv\"\n    },\n    \"matrimonios\": {\n        \"csv_file\": \"../data/clean/matrimonios_clean.csv\"\n    }\n}\n\nwith open('../data/mappings/conditionMapping.json', 'r', encoding='utf-8') as f:\n    condition_mappings = json.load(f)\n\nexisting_mappings = {\n    \"legitimacy_status\": list(condition_mappings[\"attribute_mappings\"][\"legitimacy_status\"].keys()),\n    \"social_condition\": list(condition_mappings[\"attribute_mappings\"][\"social_condition\"].keys()),\n    \"marital_status\": list(condition_mappings[\"attribute_mappings\"][\"marital_status\"].keys())\n}",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "3_termExtraction.html#pre-normalization-analysis",
    "href": "3_termExtraction.html#pre-normalization-analysis",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "Pre-Normalization Analysis",
    "text": "Pre-Normalization Analysis\nTo accurately assess the effectiveness of the mapping, we performed a series of statistical analyses on the cleaned datasets before normalization. This establishes a baseline for measuring the impact of harmonization.\n\nTextual Variation Extraction\nThese methods extract textual variations from the “conditions” columns using a regex pattern that matches the defined categories.\n\ndef extract_textual_variations_from_columns(column_pattern, dataframes_paths, min_frequency: int = 1) -&gt; dict:\n    \"\"\"\n    Extract all textual variations from columns matching a pattern.\n    This reveals how conditions were expressed in historical documents,\n    including mixed categories (e.g., marital status + age descriptors).\n    \n    Args:\n        column_pattern: Regex pattern to match column names\n        min_frequency: Minimum frequency for a term to be included\n        \n    Returns:\n        Dictionary with term frequencies and contextual metadata\n    \"\"\"\n    term_data = {}\n\n    for dataset, info in dataframes_paths.items():\n        logger.info(f\"Extracting textual variations from {dataset}...\")\n        csv_path = info[\"csv_file\"]\n\n        df = pd.read_csv(csv_path)\n\n        # Find matching columns\n        if isinstance(column_pattern, str):\n            pattern = re.compile(column_pattern)\n        else:\n            pattern = column_pattern\n            \n        matching_columns = [col for col in df.columns if pattern.search(col)]\n        logger.info(f\"Columns found: {matching_columns}\")\n\n        if not matching_columns:\n            continue\n        \n        # Extract all textual variations\n        for col in matching_columns:\n            logger.info(f\"Processing column: {col}\")\n            \n            # basic preprocessing\n            values = df[col].dropna().astype(str)\n            values = values[values != 'nan']\n            values = values[values.str.strip() != '']\n            \n            cleaned_values = values.str.lower().str.strip()\n\n            logger.info(f\"Found {len(cleaned_values)} non-empty entries\")\n\n            # Count occurrences\n            value_counts = cleaned_values.value_counts()\n            \n            for term, count in value_counts.items():\n                if term not in term_data:\n                    term_data[term] = {\n                        'frequency': 0, \n                        'columns': set(), \n                        'datasets': set(),\n                        'raw_variations': set()\n                    }\n                \n                term_data[term]['frequency'] += count\n                term_data[term]['columns'].add(col)\n                term_data[term]['datasets'].add(dataset)\n                \n                original_values = values[cleaned_values == term]\n                term_data[term]['raw_variations'].update(original_values.tolist())\n\n    # Filter by frequency\n    filtered_terms = {}\n    for term, data in term_data.items():\n        if data['frequency'] &gt;= min_frequency:\n            filtered_terms[term] = {\n                'frequency': data['frequency'],\n                'columns': list(data['columns']),\n                'datasets': list(data['datasets']),\n                'raw_variations': list(data['raw_variations'])\n            }\n    \n    return filtered_terms\n\n\n# Categories Data\n\nlegitimacy_variations = extract_textual_variations_from_columns(\n    column_pattern=re.compile(r\".*legitimacy_status.*\"),\n    min_frequency=1,\n    dataframes_paths=dataframes_paths\n)\n\nsocial_variations = extract_textual_variations_from_columns(\n    column_pattern=re.compile(r\".*social_condition.*\"),\n    min_frequency=1,\n    dataframes_paths=dataframes_paths\n)\n\nmarital_variations = extract_textual_variations_from_columns(\n    column_pattern=re.compile(r\".*marital_status.*\"),\n    min_frequency=1,\n    dataframes_paths=dataframes_paths\n)\n\n\ncategories_data = {\n    'legitimacy_status': (legitimacy_variations, existing_mappings[\"legitimacy_status\"]),\n    'social_condition': (social_variations, existing_mappings[\"social_condition\"]),\n    'marital_status': (marital_variations, existing_mappings[\"marital_status\"])\n}\n\n\n\nResults of the Exploratory Analysis\nWe performed a frequency count of the terms found in the “conditions” columns, grouping them by their main categories. The following results summarize the number of unique terms and their total frequency of appearance in the dataset:\n\nstats = {}\n\nfor category, (terms_dict, mappings) in categories_data.items():\n    frequencies = [info['frequency'] for info in terms_dict.values()]\n    stats[category] = {\n        'frequencies': frequencies,\n        'total_terms': len(frequencies),\n        'total_frequency': sum(frequencies)\n    }\n\nstats_df = pd.DataFrame(stats).T.sort_values(by='total_frequency', ascending=False).reset_index().rename(columns={'index': 'category'})\nstats_df\n\n\n\n\n\n\n\n\ncategory\nfrequencies\ntotal_terms\ntotal_frequency\n\n\n\n\n0\nsocial_condition\n[1382, 332, 29, 14, 21, 8, 33, 10, 109, 6, 6, ...\n1183\n10883\n\n\n1\nlegitimacy_status\n[996, 917, 1495, 1366, 521, 428, 383, 350, 118...\n314\n10265\n\n\n2\nmarital_status\n[400, 247, 406, 1389, 1321, 368, 24, 24, 18, 1...\n34\n4254\n\n\n\n\n\n\n\nThe data shows that the social condition category has the highest number of unique terms (1183). This suggests that many of the terms under social condition appear only once or a few times, indicating high textual variation and inconsistency — likely due to diverse wording choices by different scribes over time, as well as inconsistencies introduced during transcription.\nIn contrast, the marital status category is significantly more standardized, with only 34 unique terms used across 4,254 entries. This low variation points to a more consistent vocabulary and higher likelihood of successful harmonization.\nTo further quantify this, we computed the average frequency per term, which helps identify how often terms are reused — a proxy for redundancy and consistency.\n\nstats_df['avg_frequency_per_term'] = stats_df['total_frequency'] / stats_df['total_terms']\nstats_df['avg_frequency_per_term'] = stats_df['avg_frequency_per_term'].astype(float).round(2)\nstats_df\n\n\n\n\n\n\n\n\ncategory\nfrequencies\ntotal_terms\ntotal_frequency\navg_frequency_per_term\n\n\n\n\n0\nsocial_condition\n[1382, 332, 29, 14, 21, 8, 33, 10, 109, 6, 6, ...\n1183\n10883\n9.20\n\n\n1\nlegitimacy_status\n[996, 917, 1495, 1366, 521, 428, 383, 350, 118...\n314\n10265\n32.69\n\n\n2\nmarital_status\n[400, 247, 406, 1389, 1321, 368, 24, 24, 18, 1...\n34\n4254\n125.12\n\n\n\n\n\n\n\nAs shown above:\n\nSocial condition has the lowest average frequency per term (~9.20), confirming high fragmentation and the presence of long-tail entries that may be semantically similar but textually distinct.\nMarital status has the highest reuse rate (~125 per term), suggesting a more constrained vocabulary and consistent usage patterns.\nLegitimacy status sits in between, with moderate variation and moderate reuse.\n\nWhile all three categories benefit from textual normalization, social condition stands out as requiring special attention. Its high number of unique, low-frequency terms suggests significant noise and ambiguity that can hinder downstream analysis unless harmonized. The average frequency metric supports this interpretation and can serve as a quantifiable justification for the harmonization strategy applied in subsequent steps.\n\n\nFrequency Distribution Plots\n\ncats   = ['social_condition', 'legitimacy_status', 'marital_status']\ntitles = ['Social Condition (raw)', 'Legitimacy Status (raw)', 'Marital Status (raw)']\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 4))\n\nfor ax, (cat, title) in zip(axes, zip(cats, titles)):\n    \n    # get the list of frequencies (already sorted? if not sorted, sort descending)\n    freqs = stats_df.loc[stats_df['category'] == cat, 'frequencies'].iloc[0]\n    \n    # convert to numpy array and sort descending\n    freqs = np.array(freqs)\n    freqs = np.sort(freqs)[::-1]\n    \n    # compute ranks\n    ranks = np.arange(1, len(freqs) + 1)\n    \n    # plot rank–frequency on log–log scale\n    ax.loglog(ranks, freqs, marker='o', linestyle='-', markersize=3)\n    \n    ax.set_title(title)\n    ax.set_xlabel(\"Rank (descending frequency)\")\n    ax.set_ylabel(\"Frequency\")\n    \n    ax.grid(True, which='both', linestyle=':', alpha=0.5)\n\nplt.suptitle(\"Raw Rank–Frequency Distributions of Categorical Attributes\", y=1.03)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n## All lines in a single plot\ncats   = ['social_condition', 'legitimacy_status', 'marital_status']\ntitles = ['Social Condition', 'Legitimacy Status', 'Marital Status']\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 6))\n\nfor cat, title in zip(cats, titles):\n    # get the list of frequencies\n    freqs = stats_df.loc[stats_df['category'] == cat, 'frequencies'].iloc[0]\n    \n    # convert to numpy array and sort descending\n    freqs = np.array(freqs)\n    freqs = np.sort(freqs)[::-1]\n\n    # compute ranks\n    ranks = np.arange(1, len(freqs) + 1)\n    \n    # plot rank–frequency on log–log scale\n    ax.loglog(ranks, freqs, marker='o', linestyle='-', markersize=3, label=title)\n\n#ax.set_title(\"Raw Rank–Frequency Distributions of Categorical Attributes\")\nax.set_xlabel(\"Rank (descending frequency)\")\nax.set_ylabel(\"Frequency\")\nax.legend()\nax.grid(True, which='both', linestyle=':', alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n    \n    \n\n\n\n\n\n\n\n\n\n\nCoefficient of Variation\nThe coefficient of variation (CV) measures how much variability exists relative to the average value. In our case, we compute the CV based on the frequency distribution of unique “conditions” entries. A lower CV indicates more consistent term usage across the dataset.\n\nfrom utils import StatsMethods\n\n\nstats_df['cv'] = stats_df.apply(lambda row: StatsMethods.cv(row['frequencies'], rounding=2), axis=1)\nstats_df\n\n\n\n\n\n\n\n\ncategory\nfrequencies\ntotal_terms\ntotal_frequency\navg_frequency_per_term\ncv\n\n\n\n\n0\nsocial_condition\n[1382, 332, 29, 14, 21, 8, 33, 10, 109, 6, 6, ...\n1183\n10883\n9.20\n5.68\n\n\n1\nlegitimacy_status\n[996, 917, 1495, 1366, 521, 428, 383, 350, 118...\n314\n10265\n32.69\n4.96\n\n\n2\nmarital_status\n[400, 247, 406, 1389, 1321, 368, 24, 24, 18, 1...\n34\n4254\n125.12\n2.66\n\n\n\n\n\n\n\n\n\nShannon Entropy\nShannon entropy quantifies the uncertainty or randomness in a set of data. Social condition has the highest entropy (H) and normalized entropy (Normalized_H), demonstrating the high level of fragmentation in this category. Legitimacy and marital status show lower entropy levels, but we expect that normalization will reduce entropy across all categories, leading to more consistent usage patterns.\n\nstats_df[['H', 'H_max', 'Normalized_H', 'Redundancy']] = stats_df.apply(\n    lambda row: StatsMethods.shannon_entropy(row['frequencies'], rounding=2),\n    axis=1, result_type='expand'\n)\nstats_df[['cv', 'H', 'H_max', 'Normalized_H', 'Redundancy']]\n\n\n\n\n\n\n\n\ncv\nH\nH_max\nNormalized_H\nRedundancy\n\n\n\n\n0\n5.68\n7.29\n10.21\n0.71\n0.29\n\n\n1\n4.96\n4.43\n8.29\n0.53\n0.47\n\n\n2\n2.66\n2.50\n5.09\n0.49\n0.51\n\n\n\n\n\n\n\n\n\nZipf Distribution\nZipf’s law describes the frequency of terms in a language, where a few terms are very common while many others are rare. A Zipfian distribution indicates that a small number of terms dominate usage, while many others are used infrequently. We visualize the empirical rank-frequency distribution against the theoretical Zipf curve to assess how closely the data conforms to this pattern before normalization.\n\nstats_df['zipf_distribution'] = stats_df.apply(\n    lambda row: StatsMethods.zipf_distribution(row['frequencies'], rounding=2),\n    axis=1\n)\n\nstats_df['empirical_ranks'] = stats_df.apply(\n    lambda row: StatsMethods.empirical_rank_freq(row['frequencies'], normalize=True, rounding=2),\n    axis=1\n)\n\nstats_df[['cv', 'H', 'H_max', 'Normalized_H', 'Redundancy', 'zipf_distribution', 'empirical_ranks']]\n\n\n\n\n\n\n\n\ncv\nH\nH_max\nNormalized_H\nRedundancy\nzipf_distribution\nempirical_ranks\n\n\n\n\n0\n5.68\n7.29\n10.21\n0.71\n0.29\n[0.13, 0.07, 0.04, 0.03, 0.03, 0.02, 0.02, 0.0...\n[0.13, 0.06, 0.05, 0.03, 0.03, 0.02, 0.02, 0.0...\n\n\n1\n4.96\n4.43\n8.29\n0.53\n0.47\n[0.16, 0.08, 0.05, 0.04, 0.03, 0.03, 0.02, 0.0...\n[0.15, 0.13, 0.1, 0.09, 0.09, 0.09, 0.05, 0.04...\n\n\n2\n2.66\n2.50\n5.09\n0.49\n0.51\n[0.24, 0.12, 0.08, 0.06, 0.05, 0.04, 0.03, 0.0...\n[0.33, 0.31, 0.1, 0.09, 0.09, 0.06, 0.01, 0.01...\n\n\n\n\n\n\n\n\ndef get_series(df, cat, col):\n    return df.loc[df['category'] == cat, col].iloc[0]\n\ncats   = ['social_condition','legitimacy_status','marital_status']\ntitles = ['Social Condition','Legitimacy Status','Marital Status']\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=False)\n\nfor ax, cat, title in zip(axes, cats, titles):\n    z_before = get_series(stats_df, cat, 'zipf_distribution')\n    e_before = get_series(stats_df, cat, 'empirical_ranks')\n\n\n    # x = ranks (start at 1)\n    xb = np.arange(1, len(e_before) + 1)\n\n    # empirical \n    ax.loglog(xb, e_before, marker='o', linestyle='-',  label='Empirical')\n\n    # theoretical Zipf  (dashed)\n    ax.loglog(xb, z_before, linestyle='--', label='Zipf ref')\n\n    ax.set_title(title)\n    ax.set_xlabel(\"Rank (descending frequency)\")\n    ax.grid(True, which='both', linestyle=':', alpha=0.5)\n\naxes[0].set_ylabel(\"Probability (normalized frequency)\")\naxes[0].legend() \nplt.suptitle(\"Empirical Rank-Frequency vs Theoretical Zipf\")\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "3_termExtraction.html#normalization",
    "href": "3_termExtraction.html#normalization",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "Normalization",
    "text": "Normalization\nOur normalization strategy is designed to address the textual variation, redundancy, high entropy, and category mixing present in the “conditions” columns. The label “condition” was ambiguous even for parish priests and local officials, leading to inconsistent application across records. Without a standardized vocabulary or a consistent method for disambiguating terms, social, marital, and legitimacy-related descriptors appear intermingled in the same fields.\nTo resolve this, we developed the InferCondition.py module, which can extract specific attributes from any “conditions” column, regardless of the category in which they were recorded. For example, extract_marital_status can be applied to a social_condition column to recover marital status terms that were incorrectly placed there. When applied to the correct category, these extractors significantly reduce variability.\nAt its core, the module implements the AttributeNormalizer class, which:\n\nLoads predefined mapping dictionaries for social condition, legitimacy status, and marital status.\nApplies a multi-stage harmonization process:\n\nCase-insensitive exact match (checks if the term already matches a target form).\nWord-level match (matches any single token to the mapping).\nSubstring match (captures longer phrases containing mapped terms).\nFuzzy match (using RapidFuzz with a configurable threshold).\n\nLogs unmapped values for later review.\nProvides convenience methods to extract all attributes from a column or harmonize multiple columns in one pass.\nIncludes a function to extract unmapped tokens, removing all known mapped values and leaving residual, potentially meaningful text for further analysis.\n\nThis normalization is a foundational step in preparing the dataset for probabilistic record linkage, as it reduces noise, improves consistency, and aligns variant expressions to a controlled vocabulary without discarding historically meaningful distinctions.\n\nThis evaluation measures the effectiveness of the mapping only when applied to the correct category. It does not yet account for misfiled attributes across categories at the individual record level. A more comprehensive parsing and normalization process — applied directly to individual persona records — will be implemented in subsequent steps.\n\n\nfrom actions.generators import InferCondition\n\n\ndef normalize_textual_variations_from_columns(dataframes_paths, mapping_file, threshold=80):\n    \"\"\"\n    Normalize textual variations in multiple columns based on a mapping file.\n\n    Args:\n        column_pattern: Regex pattern to match column names\n        mapping_file: Path to the JSON mapping file\n        threshold: Level of fuzziness for matching terms (higher values are more strict)\n    \"\"\"\n\n    inferer = InferCondition.AttributeNormalizer(mapping_file=mapping_file, fuzzy_threshold=threshold)\n\n    for dataset, info in dataframes_paths.items():\n        logger.info(f\"Normalizing ALL categories in {dataset} (single pass)...\")\n        df = pd.read_csv(info[\"csv_file\"])\n\n        social_cols = [c for c in df.columns if c.lower().endswith(\"_social_condition\") or c.lower().endswith(\"_condition\")]\n        for col in social_cols:\n            logger.info(f\"Normalizing SOCIAL column: {col}\")\n            df[col] = inferer.extract_social_condition(df[col])\n\n        legitimacy_cols = [c for c in df.columns if c.lower().endswith(\"_legitimacy_status\")]\n        for col in legitimacy_cols:\n            logger.info(f\"Normalizing LEGITIMACY column: {col}\")\n            df[col] = inferer.extract_legitimacy_status(df[col])\n\n        marital_cols = [c for c in df.columns if c.lower().endswith(\"_marital_status\")]\n        for col in marital_cols:\n            logger.info(f\"Normalizing MARITAL column: {col}\")\n            df[col] = inferer.extract_marital_status(df[col])\n\n        df.to_csv(f\"../data/interim/{dataset}_normalized.csv\", index=False)\n    logger.info(\"Normalization complete.\")\n\n\nnormalize_textual_variations_from_columns(\n    dataframes_paths=dataframes_paths,\n    mapping_file=condition_mappings,\n    threshold=80,\n)\n\n\n\nnormalize_dataframes_paths = {\n    \"bautismos\": {\n        \"csv_file\": \"../data/interim/bautismos_normalized.csv\"\n    },\n    \"entierros\": {\n        \"csv_file\": \"../data/interim/entierros_normalized.csv\"\n    },\n    \"matrimonios\": {\n        \"csv_file\": \"../data/interim/matrimonios_normalized.csv\"\n    }\n}\n\n\nlegitimacy_variations_normalized = extract_textual_variations_from_columns(\n    column_pattern=re.compile(r\".*legitimacy_status.*\"),\n    min_frequency=1,\n    dataframes_paths=normalize_dataframes_paths\n)\n\nsocial_variations_normalized = extract_textual_variations_from_columns(\n    column_pattern=re.compile(r\".*social_condition.*\"),\n    min_frequency=1,\n    dataframes_paths=normalize_dataframes_paths\n)\n\nmarital_variations_normalized = extract_textual_variations_from_columns(\n    column_pattern=re.compile(r\".*marital_status.*\"),\n    min_frequency=1,\n    dataframes_paths=normalize_dataframes_paths\n)\n\n\ncategories_data_normalized = {\n    'legitimacy_status': (legitimacy_variations_normalized, existing_mappings[\"legitimacy_status\"]),\n    'social_condition': (social_variations_normalized, existing_mappings[\"social_condition\"]),\n    'marital_status': (marital_variations_normalized, existing_mappings[\"marital_status\"])\n}\n\n\nstats_normalized = {}\nfor category, (terms_dict, mappings) in categories_data_normalized.items():\n    frequencies = [info['frequency'] for info in terms_dict.values()]\n    stats_normalized[category] = {\n        'frequencies': frequencies,\n        'total_terms': len(frequencies),\n        'total_frequency': sum(frequencies)\n    }\nstats_normalized_df = pd.DataFrame(stats_normalized).T.sort_values(by='total_frequency', ascending=False).reset_index().rename(columns={'index': 'category'})\nstats_normalized_df\n\n\n\n\n\n\n\n\ncategory\nfrequencies\ntotal_terms\ntotal_frequency\n\n\n\n\n0\nlegitimacy_status\n[8925, 1278]\n2\n10203\n\n\n1\nsocial_condition\n[1663, 902, 43, 158, 5443, 331, 941]\n7\n9481\n\n\n2\nmarital_status\n[692, 777, 2715]\n3\n4184\n\n\n\n\n\n\n\n\ncats   = ['social_condition', 'legitimacy_status', 'marital_status']\ntitles = ['Social Condition', 'Legitimacy Status', 'Marital Status']\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 7))\n\n# ---- ROW 1: RAW ----\nfor ax, cat, title in zip(axes[0], cats, titles):\n    \n    # extract raw frequencies list\n    freqs_raw = stats_df.loc[stats_df['category'] == cat, 'frequencies'].iloc[0]\n    \n    # sort descending\n    freqs_raw = np.sort(np.array(freqs_raw))[::-1]\n    ranks_raw = np.arange(1, len(freqs_raw) + 1)\n    \n    ax.loglog(ranks_raw, freqs_raw, marker='o', linestyle='-', markersize=3)\n    ax.set_title(f\"{title}\")\n    ax.grid(True, which='both', linestyle=':', alpha=0.5)\n\naxes[0,0].set_ylabel(\"Frequency (raw)\")\n\n# ---- ROW 2: NORMALIZED ----\nfor ax, cat, title in zip(axes[1], cats, titles):\n    \n    # extract cleaned frequencies list\n    freqs_norm = stats_normalized_df.loc[\n        stats_normalized_df['category'] == cat, 'frequencies'\n    ].iloc[0]\n    \n    freqs_norm = np.sort(np.array(freqs_norm))[::-1]\n    ranks_norm = np.arange(1, len(freqs_norm) + 1)\n    \n    ax.loglog(ranks_norm, freqs_norm, marker='o', linestyle='-', markersize=5, color='C1')\n    ax.set_xlabel(\"Rank (descending frequency)\")\n    ax.grid(True, which='both', linestyle=':', alpha=0.5)\n\naxes[1,0].set_ylabel(\"Frequency (normalized)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ncats   = ['social_condition', 'legitimacy_status', 'marital_status']\ntitles = ['Social Condition', 'Legitimacy Status', 'Marital Status']\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 6))\n\nfor cat, title in zip(cats, titles):\n    # get the list of frequencies\n    freqs = stats_normalized_df.loc[stats_normalized_df['category'] == cat, 'frequencies'].iloc[0]\n    \n    # convert to numpy array and sort descending\n    freqs = np.array(freqs)\n    freqs = np.sort(freqs)[::-1]\n    \n    # compute ranks\n    ranks = np.arange(1, len(freqs) + 1)\n    \n    # plot rank–frequency on log–log scale\n    ax.loglog(ranks, freqs, marker='o', linestyle='-', markersize=3, label=title)\n\nax.set_title(\"Raw Rank–Frequency Distributions of Categorical Attributes\")\nax.set_xlabel(\"Rank (descending frequency)\")\nax.set_ylabel(\"Frequency\")\nax.legend()\nax.grid(True, which='both', linestyle=':', alpha=0.5)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "3_termExtraction.html#post-normalization-analysis",
    "href": "3_termExtraction.html#post-normalization-analysis",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "Post-Normalization Analysis",
    "text": "Post-Normalization Analysis\n\nInformation Retention\nAfter applying the normalization process, we assess its effectiveness by comparing key metrics before and after harmonization. This analysis evaluates information retention, consistency improvements, and the impact on distributional properties.\nAt first glance, the results show that the implementation successfully reduced dimensionality with minimal loss of information. Social condition—the most fragmented category—was reduced to just 7 unique terms, with only a 6.25% decrease in total frequency. Considering that the algorithm is designed to return None when no match is found, this reduction is both expected and encouraging, indicating that the normalization process retained most of the original data while greatly improving consistency.\n\nclean_data = stats_df['total_frequency'].astype(float)\nclean_data_normalized = stats_normalized_df['total_frequency'].astype(float)\n\n# percentage of information lost\npercentage_lost = pd.DataFrame({\n    'category': stats_df['category'],\n    'percentage_lost': ((clean_data - clean_data_normalized) / clean_data * 100).round(2)\n})\npercentage_lost\n\n\n\n\n\n\n\n\ncategory\npercentage_lost\n\n\n\n\n0\nsocial_condition\n6.25\n\n\n1\nlegitimacy_status\n7.64\n\n\n2\nmarital_status\n1.65\n\n\n\n\n\n\n\n\n\nCoefficient of Variation After Normalization\nThe coefficient of variation (CV) analysis confirms a substantial reduction in dispersion across categories after normalization. For legitimacy status, CV dropped from 4.96 to 1.06; for social condition, from 5.68 to 1.39; and for marital status, from 2.66 to 0.82. This indicates that the normalized categories are considerably more homogeneous, reducing variability while preserving most of the original data volume.\n\nstats_normalized_df['cv'] = stats_normalized_df.apply(lambda row: StatsMethods.cv(row['frequencies'], rounding=2), axis=1)\n\nstats_normalized_df\n\n\n\n\n\n\n\n\ncategory\nfrequencies\ntotal_terms\ntotal_frequency\ncv\n\n\n\n\n0\nlegitimacy_status\n[8925, 1278]\n2\n10203\n1.06\n\n\n1\nsocial_condition\n[1663, 902, 43, 158, 5443, 331, 941]\n7\n9481\n1.39\n\n\n2\nmarital_status\n[692, 777, 2715]\n3\n4184\n0.82\n\n\n\n\n\n\n\n\ncv_comparison = pd.DataFrame({\n    'category': stats_df['category'],\n    'cv_before': stats_df['cv'],\n    'cv_after': stats_normalized_df['cv']\n})\ncv_comparison\n\n\n\n\n\n\n\n\ncategory\ncv_before\ncv_after\n\n\n\n\n0\nsocial_condition\n5.68\n1.06\n\n\n1\nlegitimacy_status\n4.96\n1.39\n\n\n2\nmarital_status\n2.66\n0.82\n\n\n\n\n\n\n\n\n\nShannon Entropy After Normalization\nShannon entropy analysis reveals improved distributional properties after normalization. While entropy shows a reduction in unpredictability overall, the normalized entropy for marital status increased from 0.49 to 0.81, indicating that the relative balance among categories has improved substantially. These results demonstrate that the mapping not only improved category balance but also reduced the clutter and fragmentation in the “conditions” columns.\n\nstats_normalized_df[['H', 'H_max', 'Normalized_H', 'Redundancy']] = stats_normalized_df.apply(\n    lambda row: StatsMethods.shannon_entropy(row['frequencies'], rounding=2),\n    axis=1, result_type='expand'\n)\nstats_normalized_df[['cv', 'H', 'H_max', 'Normalized_H', 'Redundancy']]\n\n\n\n\n\n\n\n\ncv\nH\nH_max\nNormalized_H\nRedundancy\n\n\n\n\n0\n1.06\n0.54\n1.00\n0.54\n0.46\n\n\n1\n1.39\n1.86\n2.81\n0.66\n0.34\n\n\n2\n0.82\n1.29\n1.58\n0.81\n0.19\n\n\n\n\n\n\n\n\nentropy_comparison = pd.DataFrame({\n    'category': stats_df['category'],\n    'H_before': stats_df['H'],\n    'H_after': stats_normalized_df['H'],\n    'H_max_before': stats_df['H_max'],\n    'H_max_after': stats_normalized_df['H_max'],\n    'Normalized_H_before': stats_df['Normalized_H'],\n    'Normalized_H_after': stats_normalized_df['Normalized_H'],\n    'Redundancy_before': stats_df['Redundancy'],\n    'Redundancy_after': stats_normalized_df['Redundancy']\n})\nentropy_comparison\n\n\n\n\n\n\n\n\ncategory\nH_before\nH_after\nH_max_before\nH_max_after\nNormalized_H_before\nNormalized_H_after\nRedundancy_before\nRedundancy_after\n\n\n\n\n0\nsocial_condition\n7.29\n0.54\n10.21\n1.00\n0.71\n0.54\n0.29\n0.46\n\n\n1\nlegitimacy_status\n4.43\n1.86\n8.29\n2.81\n0.53\n0.66\n0.47\n0.34\n\n\n2\nmarital_status\n2.50\n1.29\n5.09\n1.58\n0.49\n0.81\n0.51\n0.19\n\n\n\n\n\n\n\n\ncategories = stats_df['category'].tolist()\n\ncv_before = stats_df['cv']\ncv_after = stats_normalized_df['cv']\n\nnh_before = stats_df['Normalized_H']\nnh_after = stats_normalized_df['Normalized_H']\n\nx = np.arange(len(categories))\nwidth = 0.35 \n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Plot CV\naxes[0].bar(x - width/2, cv_before, width, label='Before', color='skyblue')\naxes[0].bar(x + width/2, cv_after, width, label='After', color='orange')\naxes[0].set_title(\"Coefficient of Variation (CV)\")\naxes[0].set_xticks(x)\naxes[0].set_xticklabels(categories, rotation=20)\naxes[0].set_ylabel(\"CV\")\naxes[0].legend()\naxes[0].grid(axis='y', linestyle='--', alpha=0.6)\n\n# Plot Normalized Entropy\naxes[1].bar(x - width/2, nh_before, width, label='Before', color='skyblue')\naxes[1].bar(x + width/2, nh_after, width, label='After', color='orange')\naxes[1].set_title(\"Normalized Entropy (H/Hmax)\")\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(categories, rotation=20)\naxes[1].set_ylabel(\"Normalized Entropy\")\naxes[1].legend()\naxes[1].grid(axis='y', linestyle='--', alpha=0.6)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nZipf Distribution After Normalization\nAfter this radical reduction of variability, the empirical rank–frequency curves move closer to the expected Zipfian distribution, indicating that the normalization reduced fragmentation and produced a more coherent distribution of terms.\n\nLegitimacy status: The deviation from Zipf is due to the binary nature of the attribute (e.g., legitimate vs. illegitimate), not to residual noise. With only two valid terms, the imbalance between them is expected and does not affect matchability.\nSocial condition: The original long tail of rare, inconsistent terms has been greatly compressed into a small set of high-frequency categories, bringing the empirical curve into closer alignment with the theoretical model.\nMarital status: The observed mid-rank deviation from the theoretical Zipf curve reflects the small size of the category set (three terms) rather than residual noise. In such small vocabularies, differences in the natural prevalence of each term (e.g., soltero more common than viudo) produce rank–frequency shapes that diverge from the ideal Zipf slope.\n\n\nstats_normalized_df['zipf_distribution'] = stats_normalized_df.apply(\n    lambda row: StatsMethods.zipf_distribution(row['frequencies'], rounding=2),\n    axis=1\n)\n\nstats_normalized_df['empirical_ranks'] = stats_normalized_df.apply(\n    lambda row: StatsMethods.empirical_rank_freq(row['frequencies'], normalize=True, rounding=2),\n    axis=1\n)\n\nstats_normalized_df[['cv', 'H', 'H_max', 'Normalized_H', 'Redundancy', 'zipf_distribution', 'empirical_ranks']]\n\n\n\n\n\n\n\n\ncv\nH\nH_max\nNormalized_H\nRedundancy\nzipf_distribution\nempirical_ranks\n\n\n\n\n0\n1.06\n0.54\n1.00\n0.54\n0.46\n[0.67, 0.33]\n[0.87, 0.13]\n\n\n1\n1.39\n1.86\n2.81\n0.66\n0.34\n[0.39, 0.19, 0.13, 0.1, 0.08, 0.06, 0.06]\n[0.57, 0.18, 0.1, 0.1, 0.03, 0.02, 0.0]\n\n\n2\n0.82\n1.29\n1.58\n0.81\n0.19\n[0.55, 0.27, 0.18]\n[0.65, 0.19, 0.17]\n\n\n\n\n\n\n\n\ndef get_series(df, cat, col):\n    return df.loc[df['category'] == cat, col].iloc[0]\n\ncategories = stats_df['category'].tolist()\ntitles = [c.replace('_', ' ').title() for c in categories]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=False)\n\nfor ax, cat, title in zip(axes, categories, titles):\n    # BEFORE\n    z_before = get_series(stats_df, cat, 'zipf_distribution')\n    e_before = get_series(stats_df, cat, 'empirical_ranks')\n\n    # AFTER (normalized)\n    z_after  = get_series(stats_normalized_df, cat, 'zipf_distribution')\n    e_after  = get_series(stats_normalized_df, cat, 'empirical_ranks')\n\n    # x = ranks (start at 1)\n    xb = np.arange(1, len(e_before) + 1)\n    xa = np.arange(1, len(e_after)  + 1)\n\n    # empirical before/after\n    ax.loglog(xb, e_before, marker='o', linestyle='-',  label='Before (empirical)')\n    ax.loglog(xa, e_after,  marker='o', linestyle='-',  label='After (empirical)')\n\n    # theoretical Zipf before/after (dashed)\n    ax.loglog(xb, z_before, linestyle='--', label='Zipf ref (before)')\n    ax.loglog(xa, z_after,  linestyle='--', label='Zipf ref (after)')\n\n    ax.set_title(title)\n    ax.set_xlabel(\"Rank (descending frequency)\")\n    ax.grid(True, which='both', linestyle=':', alpha=0.5)\n\naxes[0].set_ylabel(\"Probability (normalized frequency)\")\naxes[0].legend()  # legend on first panel to save space\nplt.suptitle(\"Empirical Rank–Frequency vs Theoretical Zipf (Before vs After)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(1, len(categories), figsize=(15, 4), sharey=True)\n\nfor i, category in enumerate(categories):\n    theoretical = stats_normalized_df.loc[stats_normalized_df['category'] == category, 'zipf_distribution'].iloc[0]\n    empirical = stats_normalized_df.loc[stats_normalized_df['category'] == category, 'empirical_ranks'].iloc[0]\n\n    deviation = np.array(empirical) - np.array(theoretical)\n    \n    axes[i].bar(range(1, len(theoretical) + 1), deviation, color='gray', alpha=0.7)\n    axes[i].axhline(0, color='red', linestyle='--', linewidth=1)\n    axes[i].set_title(category)\n    axes[i].set_xlabel(\"Rank\")\n    if i == 0:\n        axes[i].set_ylabel(\"Deviation (Empirical - Zipf)\")\n    \nplt.suptitle(\"Deviation from Theoretical Zipf by Category\", y=1.05)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "3_termExtraction.html#conclusion",
    "href": "3_termExtraction.html#conclusion",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "Conclusion",
    "text": "Conclusion\nThe normalization process successfully compressed a large, noisy set of textual variations into a reduced, controlled vocabulary. Across all categories, the coefficient of variation decreased and normalized entropy increased, indicating greater term consistency and balance. The empirical rank–frequency curves moved closer to the theoretical Zipf distribution, showing reduced fragmentation and improved coherence in term usage.\nInformation loss was minimal — under 2% for legitimacy status and marital status, and about 13% for social condition, the most fragmented category prior to normalization. These changes substantially reduce noise and improve the dataset’s suitability for probabilistic record linkage.\nObserved deviations from a perfect Zipfian distribution in legitimacy status and marital status are explained by their inherently small vocabularies (binary and three-term sets, respectively), rather than residual inconsistency. Future iterations could selectively expand controlled vocabularies if adding more dimensions proves beneficial for specific linkage scenarios.",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "3_termExtraction.html#resulting-data",
    "href": "3_termExtraction.html#resulting-data",
    "title": "Textual Variation Analysis for ‘Conditions’ Columns",
    "section": "Resulting Data",
    "text": "Resulting Data\nThe data produced during this analysis is stored in the data/interim directory for documentation and reproducibility purposes.\n\nstats_df.to_csv(\"../data/interim/term_extraction_stats.csv\", index=False)\nstats_normalized_df.to_csv(\"../data/interim/term_extraction_stats_normalized.csv\", index=False)",
    "crumbs": [
      "Notebooks",
      "Textual Variation Analysis for 'Conditions' Columns"
    ]
  },
  {
    "objectID": "1_dataCleaning.html",
    "href": "1_dataCleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "This notebook performs comprehensive data cleaning and standardization of historical sacramental records from Sondondo. The process includes column harmonization, null value handling, temporal normalization, name standardization, and geographic data extraction, preparing the datasets for subsequent person entity extraction and probabilistic record linkage.\n# Libraries\nimport json\nimport pandas as pd\nimport numpy as np\nimport re\nfrom pathlib import Path",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#data-loading",
    "href": "1_dataCleaning.html#data-loading",
    "title": "Data Cleaning",
    "section": "1. Data Loading",
    "text": "1. Data Loading\nThe raw datasets are stored in the data/raw directory and include three types of sacramental records:\n\nbautismos.csv: Baptism records\nmatrimonios.csv: Marriage records\nentierros.csv: Burial records\n\n\nBAUTISMOS_RAW = pd.read_csv(\"../data/raw/bautismos.csv\")\nMATRIMONIOS_RAW = pd.read_csv(\"../data/raw/matrimonios.csv\")\nENTIERROS_RAW = pd.read_csv(\"../data/raw/entierros.csv\")\n\nBAUTISMOS_RAW.head()\n\n\n\n\n\n\n\n\nSecuencia\nUnidad Documental Compuesta (a la que pertenece)\nIdentificador (es recomendable seguir una secuencia numeral como la mostrada en los ejemplos)\nTítulo (incluir un título breve para cada documento)\nFolio inicial del documento (convertir como se muestra abajo)\nFolio final del documento (convertir como se muestra abajo)\nImagen inicial (estos valores serán añadidos cuando comienze el proceso de revisión de imágenes)\nImagen final (estos valores serán añadidos cuando comienze el proceso de revisión de imágenes)\nTipo de evento\nFecha aaaa-mm-dd\n...\nCondición de la madrina\nLugar de bautizo\nNotas adicionales del documento\nDescriptor Geográfico 1\nDescriptor Geográfico 2\nDescriptor Geográfico 3\nDescriptor Geográfico 4\n5\nCaracterísticas físicas (Estado de conservación de los materiales físicos)\nHistoria de revisión (de los materiales digitalizados)\n\n\n\n\n0\n1.0\nAPAucará LB L001\nB001\nBautizo. Domingo. Tributarios\n3r\n3r\nIMG_7000a\nIMG_7000a\nBautizo\n1790-10-04\n...\nNaN\nPampamarca, iglesia\nNaN\nAucara\nPampamarca\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n1\n2.0\nAPAucará LB L001\nB002\nBautizo. Dominga. Tributarios\n3r\n3r\nIMG_7000a\nIMG_7000a\nBautizo\n1790-10-06\n...\nNaN\nPampamarca, iglesia\nNaN\nAucara\nPampamarca\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n2\n3.0\nAPAucará LB L001\nB003\nBautizo. Bartola. Tributarios\n3r\n3r\nIMG_7000a\nIMG_7000a\nBautizo\n1790-10-07\n...\nNaN\nPampamarca, iglesia\nNaN\nAucara\nPampamarca\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n3\n4.0\nAPAucará LB L001\nB004\nBautizo. Francisca\n3v\n3v\nIMG_7000b\nIMG_7000b\nBautizo\n1790-10-20\n...\nNaN\nAucara, iglesia\nAbreviatura poco visible en el margen\nAucara\nNaN\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n4\n5.0\nAPAucará LB L001\nB005\nBautizo. Pedro\n3v\n3v\nIMG_7000b\nIMG_7000b\nBautizo\n1790-10-20\n...\nNaN\nAucara, iglesia\nMargen roto y manchado de tinta\nAucara\nNaN\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n\n\n5 rows × 36 columns",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#column-harmonization",
    "href": "1_dataCleaning.html#column-harmonization",
    "title": "Data Cleaning",
    "section": "2. Column Harmonization",
    "text": "2. Column Harmonization\nStandardize column names across datasets to ensure consistency. Different historical sources may use different field names for equivalent data (e.g., “nombre” vs “name”), so we map these variants to a unified schema.\n\nSchema Mapping\nColumn mappings are defined in JSON files located in data/mappings/, which specify how raw column names should be renamed to match our standardized schema.\n\n# Import the ColumnManager utility for applying schema mappings\nfrom utils.ColumnManager import ColumnManager\n\n\nbautismoMapping = Path(\"../data/mappings/bautismosMapping.json\")\nmatrimonioMapping = Path(\"../data/mappings/matrimoniosMapping.json\")\nentierroMapping = Path(\"../data/mappings/entierrosMapping.json\")\n\ncolumn_manager = ColumnManager()\n\nBAUTISMOS_HARMONIZED = column_manager.harmonize_columns(BAUTISMOS_RAW, bautismoMapping)\nMATRIMONIOS_HARMONIZED = column_manager.harmonize_columns(MATRIMONIOS_RAW, matrimonioMapping)\nENTIERROS_HARMONIZED = column_manager.harmonize_columns(ENTIERROS_RAW, entierroMapping)\n\nBAUTISMOS_HARMONIZED.head()\n\n\n\n\n\n\n\n\nid\nfile\nidentifier\ntitle\nstart_folio\nend_folio\nstart_image\nend_image\nevent_type\nevent_date\n...\ngodmother_social_condition\nevent_place\nevent_additional_notes\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\nevent_other\nrecord_physical_characteristics\nrevision_history\n\n\n\n\n0\n1.0\nAPAucará LB L001\nB001\nBautizo. Domingo. Tributarios\n3r\n3r\nIMG_7000a\nIMG_7000a\nBautizo\n1790-10-04\n...\nNaN\nPampamarca, iglesia\nNaN\nAucara\nPampamarca\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n1\n2.0\nAPAucará LB L001\nB002\nBautizo. Dominga. Tributarios\n3r\n3r\nIMG_7000a\nIMG_7000a\nBautizo\n1790-10-06\n...\nNaN\nPampamarca, iglesia\nNaN\nAucara\nPampamarca\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n2\n3.0\nAPAucará LB L001\nB003\nBautizo. Bartola. Tributarios\n3r\n3r\nIMG_7000a\nIMG_7000a\nBautizo\n1790-10-07\n...\nNaN\nPampamarca, iglesia\nNaN\nAucara\nPampamarca\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n3\n4.0\nAPAucará LB L001\nB004\nBautizo. Francisca\n3v\n3v\nIMG_7000b\nIMG_7000b\nBautizo\n1790-10-20\n...\nNaN\nAucara, iglesia\nAbreviatura poco visible en el margen\nAucara\nNaN\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n4\n5.0\nAPAucará LB L001\nB005\nBautizo. Pedro\n3v\n3v\nIMG_7000b\nIMG_7000b\nBautizo\n1790-10-20\n...\nNaN\nAucara, iglesia\nMargen roto y manchado de tinta\nAucara\nNaN\nNaN\nNaN\nNaN\nRegular\nRegistrado por Edwin Gonzales en 2023\n\n\n\n\n5 rows × 36 columns\n\n\n\n\n\nColumn Selection and Filtering\nAfter harmonization, we reduce each dataset to only the columns relevant for person entity extraction and record linkage. This simplifies downstream processing and removes fields that don’t contribute to linkage (e.g., administrative notes, scribal annotations).\n\n# Load the mapping of useful columns for each record type\n# This defines which fields are relevant for entity extraction and linkage\nuseful_columns = json.load(open(\"../data/mappings/usefulColumnsMapping.json\"))\n\n\n# Filter baptism records to useful columns only\nBAUTISMOS_HARMONIZED = BAUTISMOS_HARMONIZED[useful_columns['bautizo']]\n\n# Remove any columns that are entirely empty\nBAUTISMOS_HARMONIZED.dropna(axis=1, how='all', inplace=True)\n\nBAUTISMOS_HARMONIZED.columns\n\nIndex(['file', 'identifier', 'event_type', 'event_date', 'baptized_name',\n       'baptized_birth_place', 'baptized_birth_date',\n       'baptized_legitimacy_status', 'father_name', 'father_lastname',\n       'father_social_condition', 'mother_name', 'mother_lastname',\n       'mother_social_condition', 'parents_social_condition', 'godfather_name',\n       'godfather_lastname', 'godfather_social_condition', 'godmother_name',\n       'godmother_lastname', 'godmother_social_condition', 'event_place',\n       'event_geographic_descriptor_1', 'event_geographic_descriptor_2',\n       'event_geographic_descriptor_3', 'event_geographic_descriptor_4'],\n      dtype='object')\n\n\n\n# Filter marriage records to useful columns only\nMATRIMONIOS_HARMONIZED = MATRIMONIOS_HARMONIZED[useful_columns['matrimonio']]\n\n# Remove any columns that are entirely empty\nMATRIMONIOS_HARMONIZED.dropna(axis=1, how='all', inplace=True)\n\nMATRIMONIOS_HARMONIZED.columns\n\nIndex(['file', 'identifier', 'event_type', 'event_date', 'husband_name',\n       'husband_lastname', 'husband_social_condition',\n       'husband_marital_status', 'husband_birth_date', 'husband_birth_place',\n       'husband_resident_in', 'husband_legitimacy_status',\n       'husband_father_name', 'husband_father_lastname',\n       'husband_father_social_condition', 'husband_mother_name',\n       'husband_mother_lastname', 'husband_mother_social_condition',\n       'wife_name', 'wife_lastname', 'wife_social_condition',\n       'wife_marital_status', 'wife_birth_date', 'wife_birth_place',\n       'wife_resident_in', 'wife_legitimacy_status', 'wife_father_name',\n       'wife_father_lastname', 'wife_father_social_condition',\n       'wife_mother_name', 'wife_mother_lastname',\n       'wife_mother_social_condition', 'godparent_1_name',\n       'godparent_1_lastname', 'godparent_1_social_condition',\n       'godparent_2_name', 'godparent_2_lastname',\n       'godparent_2_social_condition', 'godparent_3_name',\n       'godparent_3_lastname', 'witness_1_name', 'witness_1_lastname',\n       'witness_2_name', 'witness_2_lastname', 'witness_3_name',\n       'witness_3_lastname', 'witness_4_name', 'witness_4_lastname',\n       'event_place', 'event_geographic_descriptor_1',\n       'event_geographic_descriptor_2', 'event_geographic_descriptor_3',\n       'event_geographic_descriptor_4', 'event_geographic_descriptor_5',\n       'event_geographic_descriptor_6'],\n      dtype='object')\n\n\n\n# Filter burial records to useful columns only\nENTIERROS_HARMONIZED = ENTIERROS_HARMONIZED[useful_columns['entierro']]\n\n# Remove any columns that are entirely empty\nENTIERROS_HARMONIZED.dropna(axis=1, how='all', inplace=True)\n\nENTIERROS_HARMONIZED.columns\n\nIndex(['file', 'identifier', 'event_type', 'event_date', 'doctrine',\n       'event_place', 'deceased_name', 'deceased_lastname',\n       'deceased_birth_date', 'deceased_birth_place',\n       'deceased_social_condition', 'deceased_marital_status',\n       'deceased_legitimacy_status', 'father_name', 'father_lastname',\n       'mother_name', 'mother_lastname', 'husband_name', 'wife_name',\n       'burial_place', 'event_geographic_descriptor_1',\n       'event_geographic_descriptor_2', 'event_geographic_descriptor_3',\n       'event_geographic_descriptor_4'],\n      dtype='object')",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#data-quality-preprocessing",
    "href": "1_dataCleaning.html#data-quality-preprocessing",
    "title": "Data Cleaning",
    "section": "3. Data Quality Preprocessing",
    "text": "3. Data Quality Preprocessing\n\nNull Value Standardization\nStandardize the representation of missing data by converting various placeholder strings (e.g., ‘-’, ‘n/a’, ‘null’) to proper np.nan values. This ensures consistent missing data handling throughout the analysis pipeline.\n\n# Define helper function to replace placeholder strings with numpy NaN\ndef replace_empty_with_na(df):\n    \"\"\"\n    Replace placeholder strings with np.nan in string columns only.\n    Handles common representations of missing data found in historical records.\n    \"\"\"\n    placeholders = {'', '-', '--', 'n/a', 'na', 'null', 'None'}\n\n    def clean_cell(val):\n        if isinstance(val, str) and val.strip().lower() in placeholders:\n            return np.nan\n        return val\n\n    return df.map(clean_cell)\n\n\nBAUTISMOS_HARMONIZED = replace_empty_with_na(BAUTISMOS_HARMONIZED)\nMATRIMONIOS_HARMONIZED = replace_empty_with_na(MATRIMONIOS_HARMONIZED)\nENTIERROS_HARMONIZED = replace_empty_with_na(ENTIERROS_HARMONIZED)\n\n\n\nEmpty Row Removal\nRemove rows where all fields are empty, as these represent blank entries or page breaks in the original record books rather than actual sacramental events.\n\nBAUTISMOS_HARMONIZED = BAUTISMOS_HARMONIZED.dropna(how='all')\nMATRIMONIOS_HARMONIZED = MATRIMONIOS_HARMONIZED.dropna(how='all')\nENTIERROS_HARMONIZED = ENTIERROS_HARMONIZED.dropna(how='all')\n\n\n\nEvent Type Corrections\n\nBaptism Event Type Errors\nTwo records in the baptism dataset have incorrect event types that need correction or removal.\n\nBAUTISMOS_HARMONIZED.loc[~(BAUTISMOS_HARMONIZED['event_type'] == 'Bautizo')]\n\n\n\n\n\n\n\n\nfile\nidentifier\nevent_type\nevent_date\nbaptized_name\nbaptized_birth_place\nbaptized_birth_date\nbaptized_legitimacy_status\nfather_name\nfather_lastname\n...\ngodfather_lastname\ngodfather_social_condition\ngodmother_name\ngodmother_lastname\ngodmother_social_condition\nevent_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\n\n\n\n\n1900\nAPAucará LB L001\nB1901\nConcurso\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n5414\nAPAucará LB L003\nB1120\n44444\n1869-09-17\nJuan\nYshua\n12 días\nHijo natural\nYgnacio\nSevidola\n...\nOriguela\nNaN\nNaN\nNaN\nNaN\nAucará\nAucará\nNaN\nNaN\nNaN\n\n\n\n\n2 rows × 26 columns\n\n\n\nEvent 1900 is basically an empty record, so we will drop it. While event 5414 requires correction:\n\nBAUTISMOS_HARMONIZED.drop(1900, inplace=True)\n\nBAUTISMOS_HARMONIZED.loc[5414, 'event_type'] = 'Bautizo'\nBAUTISMOS_HARMONIZED.iloc[5414]\n\nfile                             APAucará LB L003\nidentifier                                  B1121\nevent_type                                Bautizo\nevent_date                             1869-09-17\nbaptized_name                        Maria Isabel\nbaptized_birth_place                    Chacralla\nbaptized_birth_date                        4 días\nbaptized_legitimacy_status          Hija legítima\nfather_name                                  José\nfather_lastname                           Cerrano\nfather_social_condition                       NaN\nmother_name                               Manuela\nmother_lastname                            Avalos\nmother_social_condition                       NaN\nparents_social_condition                      NaN\ngodfather_name                                NaN\ngodfather_lastname                            NaN\ngodfather_social_condition                    NaN\ngodmother_name                            Brijida\ngodmother_lastname                            NaN\ngodmother_social_condition                    NaN\nevent_place                                Aucará\nevent_geographic_descriptor_1              Aucará\nevent_geographic_descriptor_2                 NaN\nevent_geographic_descriptor_3                 NaN\nevent_geographic_descriptor_4                 NaN\nName: 5415, dtype: object",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#temporal-data-normalization",
    "href": "1_dataCleaning.html#temporal-data-normalization",
    "title": "Data Cleaning",
    "section": "4. Temporal Data Normalization",
    "text": "4. Temporal Data Normalization\n\nDate Standardization\nEnsure all dates are in a consistent ISO format (YYYY-MM-DD) across all datasets. Historical records often contain dates in various formats (e.g., “15 de Marzo de 1850”, “3/15/1850”) that need to be parsed and standardized.\n\nfrom actions.normalizers.DatesNormalizer import DateNormalizer\n\n\nBAUTISMOS_HARMONIZED['event_date'] = DateNormalizer(BAUTISMOS_HARMONIZED['event_date']).normalize()\nBAUTISMOS_HARMONIZED['event_date']\n\n0       1790-10-04\n1       1790-10-06\n2       1790-10-07\n3       1790-10-20\n4       1790-10-20\n           ...    \n6336    1888-12-10\n6337    1888-12-11\n6338    1888-12-12\n6339    1888-12-15\n6340    1888-12-16\nName: event_date, Length: 6340, dtype: object\n\n\n\nMATRIMONIOS_HARMONIZED['event_date'] = DateNormalizer(MATRIMONIOS_HARMONIZED['event_date']).normalize()\nMATRIMONIOS_HARMONIZED['event_date']\n\n0       1816-12-06\n1       1816-12-12\n2       1817-03-05\n3       1817-03-10\n4       1817-03-12\n           ...    \n1714    1907-10-27\n1715    1908-01-13\n1716    1908-01-15\n1717    1908-02-15\n1718    1908-03-17\nName: event_date, Length: 1719, dtype: object\n\n\n\nENTIERROS_HARMONIZED['event_date'] = DateNormalizer(ENTIERROS_HARMONIZED['event_date']).normalize()\nENTIERROS_HARMONIZED['event_date']\n\n0       1846-10-06\n1       1846-10-07\n2       1846-11-02\n3       1846-12-08\n4       1847-02-23\n           ...    \n2193    1920-10-12\n2194    1920-10-19\n2195    1920-10-19\n2196    1920-10-20\n2197    1920-10-21\nName: event_date, Length: 2192, dtype: object\n\n\n\n\nBirth Date Inference\nWhen ages are recorded instead of birth dates, infer birth dates by subtracting the recorded age from the event date. This creates comparable temporal data across records that originally used different date recording conventions.\n\nfrom actions.generators.AgeInferrer import AgeInferrer\n\n\nBAUTISMOS_HARMONIZED['baptized_birth_date'] = AgeInferrer(BAUTISMOS_HARMONIZED['event_date']).infer_all(BAUTISMOS_HARMONIZED['baptized_birth_date'])\nBAUTISMOS_HARMONIZED[['event_date', 'baptized_birth_date']]\n\n\n\n\n\n\n\n\nevent_date\nbaptized_birth_date\n\n\n\n\n0\n1790-10-04\n1790-08-04\n\n\n1\n1790-10-06\n1790-08-04\n\n\n2\n1790-10-07\n1790-08-04\n\n\n3\n1790-10-20\n1790-10-15\n\n\n4\n1790-10-20\n1790-10-19\n\n\n...\n...\n...\n\n\n6336\n1888-12-10\n1888-12-09\n\n\n6337\n1888-12-11\n1888-12-07\n\n\n6338\n1888-12-12\n1888-12-06\n\n\n6339\n1888-12-15\n1888-11-30\n\n\n6340\n1888-12-16\n1888-12-01\n\n\n\n\n6340 rows × 2 columns\n\n\n\n\n### Date Validation\n\n# Check for chronologically inconsistent dates: event_date should be after baptized_birth_date\ninvalid_mask = pd.to_datetime(BAUTISMOS_HARMONIZED['event_date'], errors='coerce') &lt; pd.to_datetime(BAUTISMOS_HARMONIZED['baptized_birth_date'], errors='coerce')\nif invalid_mask.any():\n    print(\"Found invalid records:\")\n    print(BAUTISMOS_HARMONIZED[invalid_mask][['event_date', 'baptized_birth_date']])\n\nFound invalid records:\n      event_date baptized_birth_date\n135   1792-03-29          1792-04-08\n290   1794-01-01          1794-01-27\n671   1797-07-15          1797-07-24\n2814  1900-04-01          1900-04-09\n\n\n\nUnfortunately, these records were incorrectly recorded. To fix this, it is necessary to check with the original records.\n\n\nMATRIMONIOS_HARMONIZED['husband_birth_date'] = AgeInferrer(MATRIMONIOS_HARMONIZED['event_date']).infer_all(MATRIMONIOS_HARMONIZED['husband_birth_date'])\nMATRIMONIOS_HARMONIZED['wife_birth_date'] = AgeInferrer(MATRIMONIOS_HARMONIZED['event_date']).infer_all(MATRIMONIOS_HARMONIZED['wife_birth_date'])\nMATRIMONIOS_HARMONIZED[['event_date', 'husband_birth_date', 'wife_birth_date']]\n\n\n\n\n\n\n\n\nevent_date\nhusband_birth_date\nwife_birth_date\n\n\n\n\n0\n1816-12-06\nNaN\nNaN\n\n\n1\n1816-12-12\nNaN\nNaN\n\n\n2\n1817-03-05\nNaN\nNaN\n\n\n3\n1817-03-10\nNaN\nNaN\n\n\n4\n1817-03-12\nNaN\nNaN\n\n\n...\n...\n...\n...\n\n\n1714\n1907-10-27\n1882-11-01\n1880-11-01\n\n\n1715\n1908-01-13\n1880-01-19\n1879-01-19\n\n\n1716\n1908-01-15\n1886-01-19\n1888-01-19\n\n\n1717\n1908-02-15\n1883-02-20\n1886-02-19\n\n\n1718\n1908-03-17\n1880-03-23\n1879-03-24\n\n\n\n\n1719 rows × 3 columns\n\n\n\n\nENTIERROS_HARMONIZED['deceased_birth_date'] = AgeInferrer(ENTIERROS_HARMONIZED['event_date']).infer_all(ENTIERROS_HARMONIZED['deceased_birth_date'])\nENTIERROS_HARMONIZED[['event_date', 'deceased_birth_date']]\n\n\n\n\n\n\n\n\nevent_date\ndeceased_birth_date\n\n\n\n\n0\n1846-10-06\nNaN\n\n\n1\n1846-10-07\n1821-10-13\n\n\n2\n1846-11-02\n1766-11-21\n\n\n3\n1846-12-08\n1806-12-18\n\n\n4\n1847-02-23\n1797-03-06\n\n\n...\n...\n...\n\n\n2193\n1920-10-12\n1920-02-15\n\n\n2194\n1920-10-19\n1870-10-31\n\n\n2195\n1920-10-19\n1913-10-21\n\n\n2196\n1920-10-20\n1919-10-21\n\n\n2197\n1920-10-21\n1920-10-19\n\n\n\n\n2192 rows × 2 columns",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#name-standardization",
    "href": "1_dataCleaning.html#name-standardization",
    "title": "Data Cleaning",
    "section": "5. Name Standardization",
    "text": "5. Name Standardization\n\nGeneral Name Normalization\nStandardize name fields to ensure consistency for matching. This includes normalizing whitespace, removing punctuation, handling abbreviations, and standardizing capitalization.\n\nfrom actions.normalizers.NamesNormalizer import NamesNormalizer\n\n\n# Define helper function to apply name normalization to a series\ndef normalize_names_columns(series):\n    \"\"\"Apply NamesNormalizer to clean and standardize a series of name values.\"\"\"\n    namesManager = NamesNormalizer()\n    return namesManager.clean_series(series)\n\n\nnames_columns = [\n    'baptized_name', \n    'father_name', 'father_lastname',\n    'mother_name', 'mother_lastname',\n    'godfather_name', 'godfather_lastname', \n    'godmother_name', 'godmother_lastname',\n]\n\nfor col in names_columns:\n    if col in BAUTISMOS_HARMONIZED.columns:\n        BAUTISMOS_HARMONIZED[col] = normalize_names_columns(BAUTISMOS_HARMONIZED[col])\n\nBAUTISMOS_HARMONIZED[names_columns]\n\n\n\n\n\n\n\n\nbaptized_name\nfather_name\nfather_lastname\nmother_name\nmother_lastname\ngodfather_name\ngodfather_lastname\ngodmother_name\ngodmother_lastname\n\n\n\n\n0\ndomingo\nlucas\nayquipa\nsevastiana\nquispe\nvicente\nguamani\nNaN\nNaN\n\n\n1\ndominga\njuan\nlulia\njospha\ngomes\nignacio\nvarientos\nNaN\nNaN\n\n\n2\nbartola\njacinto\nquispe\njuliana\nchinchay\nNaN\nNaN\nrotonda\npocco\n\n\n3\nfrancisca\njuan\ncuebas\nclemenzia\nmanco\nNaN\nNaN\nysabel\nguillen\n\n\n4\npedro\nsantos\nmanxo\nbaleriana\narango\nNaN\nNaN\njosefa\nsantiago\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6336\nleocadio\nmiguel\npacheco\nrosa\nhuarcaya\njosé julián\nbendezú\nNaN\nNaN\n\n\n6337\nmariano concepcion\nfacundo\nvega\nsilvestra\nurbano\nfernando\nmancco\nNaN\nNaN\n\n\n6338\nambrosio\nysidro\nccasane\nrita\npalomino\njuan\ntito\nNaN\nNaN\n\n\n6339\nfrancisco\nmariano\nlopez\nleocadia\nmedina\nfeliciano\ndias\nNaN\nNaN\n\n\n6340\nlaureana\nbernarda\nchampa\nrufina\nlopez\nNaN\nNaN\nmanuela\nde la cruz\n\n\n\n\n6340 rows × 9 columns\n\n\n\n\n\nDataset-Specific Name Processing\n\nBaptisms: Surname Inference\nBaptized individuals’ surnames were not directly recorded in the original registers. We infer the surname from the father’s surname (following patrilineal naming conventions), with the mother’s surname as a fallback if the father’s is unavailable.\n\nBAUTISMOS_HARMONIZED['baptized_lastname'] = BAUTISMOS_HARMONIZED.apply(\n    lambda row: row['father_lastname'] if pd.notna(row['father_lastname']) else (\n        row['mother_lastname'] if pd.notna(row['mother_lastname']) else 'na'\n    ),\n    axis=1\n)\nBAUTISMOS_HARMONIZED['baptized_lastname']\n\n0       ayquipa\n1         lulia\n2        quispe\n3        cuebas\n4         manxo\n         ...   \n6336    pacheco\n6337       vega\n6338    ccasane\n6339      lopez\n6340     champa\nName: baptized_lastname, Length: 6340, dtype: object\n\n\n\n\nMarriages: Name Field Normalization\nMarriage records contain numerous name fields for both spouses, their parents, godparents, and witnesses. All of these require standardization.\n\nmatrimonios_names_columns = [\n    'husband_name', 'husband_lastname', \n       'husband_father_name', 'husband_father_lastname', \n       'husband_mother_name', 'husband_mother_lastname',\n       'wife_name', 'wife_lastname',\n       'wife_father_name', 'wife_father_lastname',\n       'wife_mother_name', 'wife_mother_lastname', \n       'godparent_1_name', 'godparent_1_lastname',\n       'godparent_2_name', 'godparent_2_lastname', \n       'godparent_3_name', 'godparent_3_lastname', \n       'witness_1_name', 'witness_1_lastname', \n       'witness_2_name', 'witness_2_lastname',\n       'witness_3_name', 'witness_3_lastname', \n       'witness_4_name', 'witness_4_lastname'\n]\n\nfor col in matrimonios_names_columns:\n    if col in MATRIMONIOS_HARMONIZED.columns:\n        MATRIMONIOS_HARMONIZED[col] = normalize_names_columns(MATRIMONIOS_HARMONIZED[col])\n\nMATRIMONIOS_HARMONIZED[matrimonios_names_columns]\n\n\n\n\n\n\n\n\nhusband_name\nhusband_lastname\nhusband_father_name\nhusband_father_lastname\nhusband_mother_name\nhusband_mother_lastname\nwife_name\nwife_lastname\nwife_father_name\nwife_father_lastname\n...\ngodparent_3_name\ngodparent_3_lastname\nwitness_1_name\nwitness_1_lastname\nwitness_2_name\nwitness_2_lastname\nwitness_3_name\nwitness_3_lastname\nwitness_4_name\nwitness_4_lastname\n\n\n\n\n0\njosé manl manuel\nde la roca\nacencio\nroca\nleonor\nguerrero\njuana\nrodrigues\npedro\nrodrigues\n...\nNaN\nNaN\nagustin\ncastro\nmariano\ncastro\njuan\nbaldes\nNaN\nNaN\n\n\n1\nesteban\ncastillo\nmatheo\ncastillo\nma maria\ntorres\nambrocia\ntasqui\npedro\ntasqui\n...\nNaN\nNaN\npedro\nmanco\ncarlos\ncanto\npedro\nguamani\nNaN\nNaN\n\n\n2\nalexandro\nramires\nleonor\nromani\nfranca francisca\npaucar\nsipriana\ncoillo\ncristobal\ncoillo\n...\nNaN\nNaN\nmarcelo\nllamuca\njulian\nurbano\nantonio\nurbano\nNaN\nNaN\n\n\n3\njose\ncuchu\nacencio\ncuchu\nbaleriana\nantay\ncacimira\nflores\nNaN\nNaN\n...\nNaN\nNaN\npablo\nroque\nantonio\nurbano\ncristobal\ncoillo\nNaN\nNaN\n\n\n4\ndomingo\ntito\nNaN\nNaN\nmarcela\nguauya\npetrona\nguallpatuiru\nagustin\nguallpatuiru\n...\nNaN\nNaN\nmarcelo\nllamuca\nantonio\nguamani\nmariano\nguallpatuiru\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1714\npatrocinio\nchinchay\nmiguel\nchinchay\nandrea\npolanco\nlorenza\nquispe\ngervacio\nquispe\n...\nNaN\nNaN\njuan de dios\nbarrientos\nmanuel\nespinosa\ncrisostomo\npumarino\nNaN\nNaN\n\n\n1715\ngerónimo\ncucho\nambrocio\ncucho\ngertrudis\nserrano\nteresa\njimenes\naniseto\njimenes\n...\nNaN\nNaN\nvictor\nsaravia\nmateo\naiquipa\nfelix\ncucho\nNaN\nNaN\n\n\n1716\njosé\ncoro\nfelix\ncoro\nnatividad\ncucho\nemilia\nhuamani\npatricio\nhuamani\n...\nNaN\nNaN\npablo\nde la cruz\nvictor\nsaravia\nmarcelo\nramos\nNaN\nNaN\n\n\n1717\npedro\ngutierres\nruperto\ngutierrez\nmicaila\noscco\njuliana\nhuarcaya\nhilario\nhuarcaya\n...\nNaN\nNaN\nrafael\ndelgado\njosé\nvivanco\nagustin\nvicente\nNaN\nNaN\n\n\n1718\nbenito\nsanchez\ntiburcio\nsanchez\nlorenza\naymi\nteresa\npoma\nbernardo\npoma\n...\nNaN\nNaN\nsantos\nespejo\nfelix\nsanches\nmariano\nurbano\nNaN\nNaN\n\n\n\n\n1719 rows × 26 columns\n\n\n\n\nentierros_names_columns = [\n    \"deceased_name\", \"deceased_lastname\",\n    \"father_name\", \"father_lastname\",\n    \"mother_name\", \"mother_lastname\",\n    \"husband_name\", \"wife_name\",\n]\n\nfor col in entierros_names_columns:\n    if col in ENTIERROS_HARMONIZED.columns:\n        ENTIERROS_HARMONIZED[col] = normalize_names_columns(ENTIERROS_HARMONIZED[col])\n\nENTIERROS_HARMONIZED[entierros_names_columns]\n\n\n\n\n\n\n\n\ndeceased_name\ndeceased_lastname\nfather_name\nfather_lastname\nmother_name\nmother_lastname\nhusband_name\nwife_name\n\n\n\n\n0\njulian\nxavies\nNaN\nNaN\nNaN\nNaN\nNaN\nmercedes lupa\n\n\n1\njoce\nraime\nNaN\nNaN\nNaN\nNaN\nNaN\nfrancisca cucho\n\n\n2\nmartina\ncondori\nNaN\nNaN\nNaN\nNaN\nluciano ccoyllo\nNaN\n\n\n3\ndorotea\nccoyllo\nNaN\nNaN\nNaN\nNaN\njosé espinosa\nNaN\n\n\n4\nmaría\nromani\nNaN\nNaN\nNaN\nNaN\nmariano huallpatuiro\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2193\nnieves\nhuallpatuero\npatrocinio\nhuallpatuero\nteresa\nurbano\nNaN\nNaN\n\n\n2194\nsinforiano\nhuamani\neustaquio\nhuamani\nmartina\nllamoca\nNaN\ngregoria ccoillo\n\n\n2195\nsalomé\ncondori\nsebastian\ncondori\nanacla\nroque\nNaN\nNaN\n\n\n2196\nmaría\nchinchay\nabdon\nchinchay\nfloriza\nlopez\nNaN\nNaN\n\n\n2197\nfortunato\nflorez\ncecilio\nflorez\nguadalupe\nramos\nNaN\nNaN\n\n\n\n\n2192 rows × 8 columns\n\n\n\n\n\nBurials: Name Field Normalization\nBurial records contain name fields for the deceased and their family members.\n\n\nBurials: Full Name Splitting\nIn burial records, deceased spouses (husband/wife) were recorded as full names in a single field. We need to split these into separate first name and surname fields for consistency with other datasets.\n\n# Define helper function to split full names into first name and surname\ndef name_splitter(name):\n    \"\"\"\n    Split a full name into first name and surname components.\n    Handles compound surnames like 'de la' and multi-word first names.\n    \"\"\"\n    if pd.isnull(name):\n        return np.nan, np.nan\n\n    name_parts = name.split()\n    if len(name_parts) &gt; 2:\n        if \"de la\" in name:\n            return name_parts[0], \" \".join(name_parts[1:])\n        return \" \".join(name_parts[0:2]), \" \".join(name_parts[2:])\n    return name_parts[0], name_parts[1] if len(name_parts) &gt; 1 else np.nan\n\n\nENTIERROS_HARMONIZED[['husband_name', 'husband_lastname']] = ENTIERROS_HARMONIZED['husband_name'].apply(name_splitter).apply(pd.Series)\nENTIERROS_HARMONIZED[['wife_name', 'wife_lastname']] = ENTIERROS_HARMONIZED['wife_name'].apply(name_splitter).apply(pd.Series)",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#geographic-data-extraction",
    "href": "1_dataCleaning.html#geographic-data-extraction",
    "title": "Data Cleaning",
    "section": "6. Geographic Data Extraction",
    "text": "6. Geographic Data Extraction\n\nPlace Name Recognition\nExtract place name entities from text fields using Named Entity Recognition (NER). Historical records often contain place names embedded within longer descriptive text (e.g., “natural de la villa de Sondondo”), which need to be identified and extracted for geographic analysis.\n\nfrom actions.extractors import placeRecognition\n\nextractor = placeRecognition.PlaceExtractor()\n\n\nbautismos_place_columns = [\n    'baptized_birth_place', 'event_place', 'event_geographic_descriptor_1',\n        'event_geographic_descriptor_2', 'event_geographic_descriptor_3',\n        'event_geographic_descriptor_4'\n]\n\nBAUTISMOS_PLACES_RAW = BAUTISMOS_HARMONIZED[bautismos_place_columns]\n\nfor col in bautismos_place_columns:\n    if col in BAUTISMOS_HARMONIZED.columns:\n        BAUTISMOS_HARMONIZED[col] = extractor.extract_places_per_row(BAUTISMOS_HARMONIZED[col])\n\nBAUTISMOS_HARMONIZED[bautismos_place_columns]\n\n\n\n\n\n\n\n\nbaptized_birth_place\nevent_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\n\n\n\n\n0\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\n\n\n1\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\n\n\n2\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\n\n\n3\nNaN\nAucara\nAucara\nNaN\nNaN\nNaN\n\n\n4\nNaN\nAucara\nAucara\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n6336\nNaN\nAucará\nAucará\nAucará\nNaN\nNaN\n\n\n6337\nNaN\nAucará\nAucará\nAucará\nNaN\nNaN\n\n\n6338\nNaN\nAucará\nAucará\nMayobamba\nNaN\nNaN\n\n\n6339\nNaN\nAucará\nAucará\nHuaicahuacho\nNaN\nNaN\n\n\n6340\nNaN\nAucará\nAucará\nChacralla\nNaN\nNaN\n\n\n\n\n6340 rows × 6 columns\n\n\n\n\nMarriage Place Extraction\n\nmatrimonios_place_columns = [\n    'husband_birth_place',\n       'husband_resident_in', \n       'wife_birth_place', 'wife_resident_in', \n       'event_place', 'event_geographic_descriptor_1', 'event_geographic_descriptor_2',\n       'event_geographic_descriptor_3', 'event_geographic_descriptor_4',\n       'event_geographic_descriptor_5', 'event_geographic_descriptor_6'\n]\n\nMATRIMONIOS_PLACES_RAW = MATRIMONIOS_HARMONIZED[matrimonios_place_columns]\n\nfor col in matrimonios_place_columns:\n    if col in MATRIMONIOS_HARMONIZED.columns:\n        MATRIMONIOS_HARMONIZED[col] = extractor.extract_places_per_row(MATRIMONIOS_HARMONIZED[col])\n\nMATRIMONIOS_HARMONIZED[matrimonios_place_columns]\n\n\n\n\n\n\n\n\nhusband_birth_place\nhusband_resident_in\nwife_birth_place\nwife_resident_in\nevent_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\nevent_geographic_descriptor_5\nevent_geographic_descriptor_6\n\n\n\n\n0\nCiudad de Huamanga\nAucara\nNaN\nNaN\nAucara\nAucara\nHuamanga\nCoracora\nNaN\nNaN\nNaN\n\n\n1\nNaN\nNaN\nNaN\nNaN\nAucara\nAucara\nColca\nNaN\nNaN\nNaN\nNaN\n\n\n2\nPampamarca\nNaN\nPampamarca\nNaN\nAucara\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n3\nPampamarca\nNaN\nPampamarca\nNaN\nPampamarca|santa iglesia\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n4\nNaN\nNaN\nNaN\nNaN\nPampamarca|santa iglesia\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1714\nPampamarca\nNaN\nPampamarca\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n1715\nChacralla\nNaN\nChacralla\nNaN\nChacralla, iglesia vice-parroquial\nAucara\nChacralla\nNaN\nNaN\nNaN\nNaN\n\n\n1716\nChacralla\nNaN\nChacralla\nNaN\nChacralla, iglesia vice-parroquial\nAucara\nChacralla\nNaN\nNaN\nNaN\nNaN\n\n\n1717\nNaN\nAucara\nNaN\nAucara\nAucara\nAucara\nQueca\nNaN\nNaN\nNaN\nNaN\n\n\n1718\nPampamarca\nNaN\nPampamarca\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n1719 rows × 11 columns\n\n\n\n\n\nBurial Place Extraction\n\nentierros_place_columns = [\n    'event_place', 'deceased_birth_place', 'burial_place', 'event_geographic_descriptor_1',\n    'event_geographic_descriptor_2', 'event_geographic_descriptor_3',\n    'event_geographic_descriptor_4'\n]\n\nENTIERROS_PLACES_RAW = ENTIERROS_HARMONIZED[entierros_place_columns]\n\nfor col in entierros_place_columns:\n    if col in ENTIERROS_HARMONIZED.columns:\n        ENTIERROS_HARMONIZED[col] = extractor.extract_places_per_row(ENTIERROS_HARMONIZED[col])\n\nENTIERROS_HARMONIZED[entierros_place_columns]\n\n\n\n\n\n\n\n\nevent_place\ndeceased_birth_place\nburial_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\n\n\n\n\n0\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n1\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n3\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n4\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2193\nAucara\nSanta Ana de Aucara\nNaN\nAucara\nSanta Ana de Aucara\nNaN\nNaN\n\n\n2194\nAucara\nPampamarca\nNaN\nAucara\nPampamarca\nNaN\nNaN\n\n\n2195\nAucara\nSanta Ana de Aucara\nNaN\nAucara\nSanta Ana de Aucara\nNaN\nNaN\n\n\n2196\nAucara\nAucara\nNaN\nAucara\nNaN\nNaN\nNaN\n\n\n2197\nAucara\nAucara\nNaN\nAucara\nNaN\nNaN\nNaN\n\n\n\n\n2192 rows × 7 columns\n\n\n\n\n### Raw Place Export\n\n# Extract all unique place names from all datasets and save for subsequent normalization\n# in the place mapping notebook (2_placeMapping.ipynb)\nfrom utils import UniqueValues\n\nuniqueValues = UniqueValues.UniqueValuesExtractor(\n    [BAUTISMOS_PLACES_RAW, MATRIMONIOS_PLACES_RAW, ENTIERROS_PLACES_RAW]\n).get_unique_values(return_dataframe=True)\n\nuniqueValues.to_csv(\"../data/raw/raw_places.csv\", index=False) # type: ignore",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#export-cleaned-data",
    "href": "1_dataCleaning.html#export-cleaned-data",
    "title": "Data Cleaning",
    "section": "7. Export Cleaned Data",
    "text": "7. Export Cleaned Data\nAll cleaned datasets are exported to the data/clean/ directory for use in subsequent analysis notebooks (term extraction, person entity creation, and record linkage).\n\nclean_data_folder = Path(\"../data/clean/\")\n\n# Fill NaN values for consistency\nBAUTISMOS_HARMONIZED = BAUTISMOS_HARMONIZED.fillna(value=np.nan)\nMATRIMONIOS_HARMONIZED = MATRIMONIOS_HARMONIZED.fillna(value=np.nan)\nENTIERROS_HARMONIZED = ENTIERROS_HARMONIZED.fillna(value=np.nan)\n\nBAUTISMOS_HARMONIZED.to_csv(clean_data_folder / \"bautismos_clean.csv\", index=False)\nMATRIMONIOS_HARMONIZED.to_csv(clean_data_folder / \"matrimonios_clean.csv\", index=False)\nENTIERROS_HARMONIZED.to_csv(clean_data_folder / \"entierros_clean.csv\", index=False)",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "1_dataCleaning.html#summary",
    "href": "1_dataCleaning.html#summary",
    "title": "Data Cleaning",
    "section": "Summary",
    "text": "Summary\nThis notebook successfully cleaned and standardized three sacramental record datasets:\nKey transformations applied: 1. Column Harmonization: Unified schema across heterogeneous historical sources 2. Null Standardization: Converted diverse missing data representations to np.nan 3. Temporal Normalization: Standardized dates to ISO format and inferred birth dates from ages 4. Name Standardization: Applied consistent name cleaning and inferred missing surnames 5. Geographic Extraction: Identified place name entities using NER 6. Data Export: Saved cleaned datasets to data/clean/ for downstream analysis\nOutputs: - bautismos_clean.csv: {len(BAUTISMOS_HARMONIZED)} baptism records - matrimonios_clean.csv: {len(MATRIMONIOS_HARMONIZED)} marriage records - entierros_clean.csv: {len(ENTIERROS_HARMONIZED)} burial records - raw_places.csv: Raw place names for normalization in notebook 2\nThe cleaned data is now ready for term extraction analysis (notebook 3), place name normalization (notebook 2), and person entity creation (notebook 4).",
    "crumbs": [
      "Notebooks",
      "Data Cleaning"
    ]
  },
  {
    "objectID": "docpages/metadata_dictionary.html",
    "href": "docpages/metadata_dictionary.html",
    "title": "Metadata Dictionary",
    "section": "",
    "text": "Show code\nlibrary(tidyverse)\nThis metadata dictionary provides comprehensive documentation for all datasets in the data/clean/ folder. Each section includes the dataset structure, a description of the table’s purpose, and detailed field-level documentation with expected data types and descriptions.\nThe datasets represent historical parish records from Sondondo, Peru, covering vital events (baptisms, marriages, and burials) as well as derived entities (places and personas). All records have been cleaned, normalized, and harmonized to facilitate analysis and integration.",
    "crumbs": [
      "Documentation",
      "Metadata Dictionary"
    ]
  },
  {
    "objectID": "docpages/metadata_dictionary.html#events",
    "href": "docpages/metadata_dictionary.html#events",
    "title": "Metadata Dictionary",
    "section": "Events",
    "text": "Events\nEvent tables document vital religious ceremonies recorded in parish registers: baptisms, marriages, and burials. These records form the primary source material for the project, capturing not only the principal individuals involved but also family relationships, social conditions, and geographic information. Each event type has its own structure reflecting the specific information recorded for that ceremony.\n\nBaptisms\n\n\n\n\n\n\nDataset Structure\n\n\n\n\n\n\n\nShow code\nbaptisms &lt;- readr::read_csv(\"../../data/clean/bautismos_clean.csv\", show_col_types = FALSE)\nbaptisms %&gt;% glimpse()\n\n\nRows: 6,340\nColumns: 27\n$ file                          &lt;chr&gt; \"APAucará LB L001\", \"APAucará LB L001\", …\n$ identifier                    &lt;chr&gt; \"B001\", \"B002\", \"B003\", \"B004\", \"B005\", …\n$ event_type                    &lt;chr&gt; \"Bautizo\", \"Bautizo\", \"Bautizo\", \"Bautiz…\n$ event_date                    &lt;date&gt; 1790-10-04, 1790-10-06, 1790-10-07, 179…\n$ baptized_name                 &lt;chr&gt; \"domingo\", \"dominga\", \"bartola\", \"franci…\n$ baptized_birth_place          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ baptized_birth_date           &lt;date&gt; 1790-08-04, 1790-08-04, 1790-08-04, 179…\n$ baptized_legitimacy_status    &lt;chr&gt; \"Hijo legitimo\", \"Hija legitima\", \"Hija …\n$ father_name                   &lt;chr&gt; \"lucas\", \"juan\", \"jacinto\", \"juan\", \"san…\n$ father_lastname               &lt;chr&gt; \"ayquipa\", \"lulia\", \"quispe\", \"cuebas\", …\n$ father_social_condition       &lt;chr&gt; NA, NA, NA, \"Mestizo\", NA, NA, NA, NA, N…\n$ mother_name                   &lt;chr&gt; \"sevastiana\", \"jospha\", \"juliana\", \"clem…\n$ mother_lastname               &lt;chr&gt; \"quispe\", \"gomes\", \"chinchay\", \"manco\", …\n$ mother_social_condition       &lt;chr&gt; NA, NA, NA, \"India libre\", NA, NA, \"solt…\n$ parents_social_condition      &lt;chr&gt; \"Indios tributarios de Pampamarca\", \"Ind…\n$ godfather_name                &lt;chr&gt; \"vicente\", \"ignacio\", NA, NA, NA, NA, NA…\n$ godfather_lastname            &lt;chr&gt; \"guamani\", \"varientos\", NA, NA, NA, NA, …\n$ godfather_social_condition    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ godmother_name                &lt;chr&gt; NA, NA, \"rotonda\", \"ysabel\", \"josefa\", \"…\n$ godmother_lastname            &lt;chr&gt; NA, NA, \"pocco\", \"guillen\", \"santiago\", …\n$ godmother_social_condition    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ event_place                   &lt;chr&gt; \"Pampamarca\", \"Pampamarca\", \"Pampamarca\"…\n$ event_geographic_descriptor_1 &lt;chr&gt; \"Aucara\", \"Aucara\", \"Aucara\", \"Aucara\", …\n$ event_geographic_descriptor_2 &lt;chr&gt; \"Pampamarca\", \"Pampamarca\", \"Pampamarca\"…\n$ event_geographic_descriptor_3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ event_geographic_descriptor_4 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ baptized_lastname             &lt;chr&gt; \"ayquipa\", \"lulia\", \"quispe\", \"cuebas\", …\n\n\n\n\n\n\n\n\n\n\n\n\n\nProperty\nExpected Type\nDescription\n\n\n\n\nfile\nText\nSource file name from which the record was extracted\n\n\nidentifier\nText\nSecuential identifier for the baptism event\n\n\nevent_type\nText\nType of event (Bautizo)\n\n\nevent_date\nDate\nDate of the baptism event in ISO 8601 format\n\n\nbaptized_name\nText\nNormalized first and middle name(s) of the baptized individual\n\n\nbaptized_lastname\nText\nNormalized or inferred surname(s) of the baptized individual\n\n\nbaptized_birth_place\nText\nPlace of birth of the baptized individual\n\n\nbaptized_birth_date\nDate\nDate of birth of the baptized individual in ISO 8601 format\n\n\nbaptized_legitimacy_status\nText\nLegitimacy status at birth (legitimo, ilegitimo)\n\n\nfather_name\nText\nNormalized name of the father\n\n\nfather_lastname\nText\nNormalized or inferred surname(s) of the father\n\n\nfather_social_condition\nText\nSocial, ethnical, or political marker of the father (mestizo, indio, tributario, vecino)\n\n\nmother_name\nText\nNormalized name of the mother\n\n\nmother_lastname\nText\nNormalized or inferred surname(s) of the mother\n\n\nmother_social_condition\nText\nSocial, ethnical, or political marker of the mother (mestizo, indio, tributario, vecino)\n\n\nparents_social_condition\nText\nCombined social condition of both parents\n\n\ngodfather_name\nText\nNormalized name of the godfather\n\n\ngodfather_lastname\nText\nNormalized or inferred surname(s) of the godfather\n\n\ngodfather_social_condition\nText\nSocial, ethnical, or political marker of the godfather (mestizo, indio, tributario, vecino)\n\n\ngodmother_name\nText\nNormalized name of the godmother\n\n\ngodmother_lastname\nText\nNormalized or inferred surname(s) of the godmother\n\n\ngodmother_social_condition\nText\nSocial, ethnical, or political marker of the godmother (mestizo, indio, tributario, vecino)\n\n\nevent_place\nText\nPlace where the baptism event took place\n\n\nevent_geographic_descriptor_1\nText\nPlace or location mentioned in the record\n\n\nevent_geographic_descriptor_2\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_3\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_4\nText\nAdditional place or location mentioned in the record\n\n\n\n\n\nMarriages\n\n\n\n\n\n\nDataset Structure\n\n\n\n\n\n\n\nShow code\nmarriages &lt;- readr::read_csv(\"../../data/clean/matrimonios_clean.csv\", show_col_types = FALSE)\nmarriages %&gt;% glimpse()\n\n\nRows: 1,719\nColumns: 55\n$ file                            &lt;chr&gt; \"APAucará LM L001\", \"APAucará LM L001\"…\n$ identifier                      &lt;chr&gt; \"M001\", \"M002\", \"M003\", \"M004\", \"M005\"…\n$ event_type                      &lt;chr&gt; \"Matrimonio\", \"Matrimonio\", \"Matrimoni…\n$ event_date                      &lt;date&gt; 1816-12-06, 1816-12-12, 1817-03-05, 1…\n$ husband_name                    &lt;chr&gt; \"josé manl manuel\", \"esteban\", \"alexan…\n$ husband_lastname                &lt;chr&gt; \"de la roca\", \"castillo\", \"ramires\", \"…\n$ husband_social_condition        &lt;chr&gt; \"don, vecinos de este pueblo [Aucara]\"…\n$ husband_marital_status          &lt;chr&gt; \"soltero\", \"soltero\", \"soltero\", \"solt…\n$ husband_birth_date              &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ husband_birth_place             &lt;chr&gt; \"Ciudad de Huamanga\", NA, \"Pampamarca\"…\n$ husband_resident_in             &lt;chr&gt; \"Aucara\", NA, NA, NA, NA, NA, NA, NA, …\n$ husband_legitimacy_status       &lt;chr&gt; NA, \"legítimo\", \"legítimo\", \"legítimo\"…\n$ husband_father_name             &lt;chr&gt; \"acencio\", \"matheo\", \"leonor\", \"acenci…\n$ husband_father_lastname         &lt;chr&gt; \"roca\", \"castillo\", \"romani\", \"cuchu\",…\n$ husband_father_social_condition &lt;chr&gt; \"don, vecinos de este pueblo [Aucara]\"…\n$ husband_mother_name             &lt;chr&gt; \"leonor\", \"ma maria\", \"franca francisc…\n$ husband_mother_lastname         &lt;chr&gt; \"guerrero\", \"torres\", \"paucar\", \"antay…\n$ husband_mother_social_condition &lt;chr&gt; \"doña, vecinos de este pueblo [Aucara]…\n$ wife_name                       &lt;chr&gt; \"juana\", \"ambrocia\", \"sipriana\", \"caci…\n$ wife_lastname                   &lt;chr&gt; \"rodrigues\", \"tasqui\", \"coillo\", \"flor…\n$ wife_social_condition           &lt;chr&gt; \"doña, vecinos de este pueblo [Aucara]…\n$ wife_marital_status             &lt;chr&gt; \"soltera\", \"soltera\", \"soltera\", \"solt…\n$ wife_birth_date                 &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wife_birth_place                &lt;chr&gt; NA, NA, \"Pampamarca\", \"Pampamarca\", NA…\n$ wife_resident_in                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wife_legitimacy_status          &lt;chr&gt; \"legítima\", \"legítima\", \"legítima\", NA…\n$ wife_father_name                &lt;chr&gt; \"pedro\", \"pedro\", \"cristobal\", NA, \"ag…\n$ wife_father_lastname            &lt;chr&gt; \"rodrigues\", \"tasqui\", \"coillo\", NA, \"…\n$ wife_father_social_condition    &lt;chr&gt; \"don, vecinos de este pueblo [Aucara]\"…\n$ wife_mother_name                &lt;chr&gt; \"magdalena\", \"ma maria\", \"ma maria\", \"…\n$ wife_mother_lastname            &lt;chr&gt; \"sotelo\", \"palomino\", \"guallpatuiru\", …\n$ wife_mother_social_condition    &lt;chr&gt; \"doña, vecinos de este pueblo [Aucara]…\n$ godparent_1_name                &lt;chr&gt; \"ygnacio\", \"apolin apolinario\", \"pablo…\n$ godparent_1_lastname            &lt;chr&gt; \"baroti\", \"condori\", \"roque\", \"llamuca…\n$ godparent_1_social_condition    &lt;chr&gt; \"don\", NA, NA, NA, NA, NA, NA, NA, NA,…\n$ godparent_2_name                &lt;chr&gt; \"magda magdalena\", \"petrona\", \"ma mari…\n$ godparent_2_lastname            &lt;chr&gt; \"sotelo\", \"ventura\", \"puma\", \"guamani\"…\n$ godparent_2_social_condition    &lt;chr&gt; \"doña\", NA, NA, NA, NA, NA, NA, \"doña\"…\n$ godparent_3_name                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ godparent_3_lastname            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ witness_1_name                  &lt;chr&gt; \"agustin\", \"pedro\", \"marcelo\", \"pablo\"…\n$ witness_1_lastname              &lt;chr&gt; \"castro\", \"manco\", \"llamuca\", \"roque\",…\n$ witness_2_name                  &lt;chr&gt; \"mariano\", \"carlos\", \"julian\", \"antoni…\n$ witness_2_lastname              &lt;chr&gt; \"castro\", \"canto\", \"urbano\", \"urbano\",…\n$ witness_3_name                  &lt;chr&gt; \"juan\", \"pedro\", \"antonio\", \"cristobal…\n$ witness_3_lastname              &lt;chr&gt; \"baldes\", \"guamani\", \"urbano\", \"coillo…\n$ witness_4_name                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ witness_4_lastname              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ event_place                     &lt;chr&gt; \"Aucara\", \"Aucara\", \"Aucara\", \"Pampama…\n$ event_geographic_descriptor_1   &lt;chr&gt; \"Aucara\", \"Aucara\", \"Aucara\", \"Aucara\"…\n$ event_geographic_descriptor_2   &lt;chr&gt; \"Huamanga\", \"Colca\", \"Pampamarca\", \"Pa…\n$ event_geographic_descriptor_3   &lt;chr&gt; \"Coracora\", NA, NA, NA, NA, NA, NA, NA…\n$ event_geographic_descriptor_4   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ event_geographic_descriptor_5   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ event_geographic_descriptor_6   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\nThe marriages table contains cleaned and standardized records of marriage events extracted from parish registers. Each row represents a unique marriage event with associated attributes for both spouses, their families, witnesses, and godparents.\n\n\n\n\n\n\n\n\nProperty\nExpected Type\nDescription\n\n\n\n\nfile\nText\nSource file name from which the record was extracted\n\n\nidentifier\nText\nSequential identifier for the marriage event\n\n\nevent_type\nText\nType of event (Matrimonio)\n\n\nevent_date\nDate\nDate of the marriage event in ISO 8601 format\n\n\nhusband_name\nText\nNormalized first and middle name(s) of the husband\n\n\nhusband_lastname\nText\nNormalized or inferred surname(s) of the husband\n\n\nhusband_social_condition\nText\nSocial, ethnical, or political marker of the husband (mestizo, indio, tributario, vecino, don)\n\n\nhusband_marital_status\nText\nMarital status of the husband at the time of marriage (soltero, viudo)\n\n\nhusband_birth_date\nDate\nDate of birth of the husband in ISO 8601 format\n\n\nhusband_birth_place\nText\nPlace of birth of the husband\n\n\nhusband_resident_in\nText\nRecorded place of residence of the husband at the time of the event\n\n\nhusband_legitimacy_status\nText\nLegitimacy status of the husband at birth (legítimo, ilegitimo, natural)\n\n\nhusband_father_name\nText\nNormalized name of the husband’s father\n\n\nhusband_father_lastname\nText\nNormalized or inferred surname(s) of the husband’s father\n\n\nhusband_father_social_condition\nText\nSocial, ethnical, or political marker of the husband’s father (mestizo, indio, tributario, vecino, don)\n\n\nhusband_mother_name\nText\nNormalized name of the husband’s mother\n\n\nhusband_mother_lastname\nText\nNormalized or inferred surname(s) of the husband’s mother\n\n\nhusband_mother_social_condition\nText\nSocial, ethnical, or political marker of the husband’s mother (mestizo, indio, tributario, vecino, doña)\n\n\nwife_name\nText\nNormalized first and middle name(s) of the wife\n\n\nwife_lastname\nText\nNormalized or inferred surname(s) of the wife\n\n\nwife_social_condition\nText\nSocial, ethnical, or political marker of the wife (mestizo, indio, tributario, vecino, doña)\n\n\nwife_marital_status\nText\nMarital status of the wife at the time of marriage (soltera, viuda)\n\n\nwife_birth_date\nDate\nDate of birth of the wife in ISO 8601 format\n\n\nwife_birth_place\nText\nPlace of birth of the wife\n\n\nwife_resident_in\nText\nRecorded place of residence of the wife at the time of the event\n\n\nwife_legitimacy_status\nText\nLegitimacy status of the wife at birth (legítima, ilegitima, natural)\n\n\nwife_father_name\nText\nNormalized name of the wife’s father\n\n\nwife_father_lastname\nText\nNormalized or inferred surname(s) of the wife’s father\n\n\nwife_father_social_condition\nText\nSocial, ethnical, or political marker of the wife’s father (mestizo, indio, tributario, vecino, don)\n\n\nwife_mother_name\nText\nNormalized name of the wife’s mother\n\n\nwife_mother_lastname\nText\nNormalized or inferred surname(s) of the wife’s mother\n\n\nwife_mother_social_condition\nText\nSocial, ethnical, or political marker of the wife’s mother (mestizo, indio, tributario, vecino, doña)\n\n\ngodparent_1_name\nText\nNormalized name of the first godparent\n\n\ngodparent_1_lastname\nText\nNormalized or inferred surname(s) of the first godparent\n\n\ngodparent_1_social_condition\nText\nSocial, ethnical, or political marker of the first godparent (mestizo, indio, tributario, vecino, don, doña)\n\n\ngodparent_2_name\nText\nNormalized name of the second godparent\n\n\ngodparent_2_lastname\nText\nNormalized or inferred surname(s) of the second godparent\n\n\ngodparent_2_social_condition\nText\nSocial, ethnical, or political marker of the second godparent (mestizo, indio, tributario, vecino, don, doña)\n\n\ngodparent_3_name\nText\nNormalized name of the third godparent (when applicable)\n\n\ngodparent_3_lastname\nText\nNormalized or inferred surname(s) of the third godparent (when applicable)\n\n\nwitness_1_name\nText\nNormalized name of the first witness\n\n\nwitness_1_lastname\nText\nNormalized or inferred surname(s) of the first witness\n\n\nwitness_2_name\nText\nNormalized name of the second witness\n\n\nwitness_2_lastname\nText\nNormalized or inferred surname(s) of the second witness\n\n\nwitness_3_name\nText\nNormalized name of the third witness (when applicable)\n\n\nwitness_3_lastname\nText\nNormalized or inferred surname(s) of the third witness (when applicable)\n\n\nwitness_4_name\nText\nNormalized name of the fourth witness (when applicable)\n\n\nwitness_4_lastname\nText\nNormalized or inferred surname(s) of the fourth witness (when applicable)\n\n\nevent_place\nText\nPlace where the marriage event took place\n\n\nevent_geographic_descriptor_1\nText\nPlace or location mentioned in the record\n\n\nevent_geographic_descriptor_2\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_3\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_4\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_5\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_6\nText\nAdditional place or location mentioned in the record\n\n\n\n\n\nBurials\n\n\n\n\n\n\nDataset Structure\n\n\n\n\n\n\n\nShow code\nburials &lt;- readr::read_csv(\"../../data/clean/entierros_clean.csv\", show_col_types = FALSE)\nburials %&gt;% glimpse()\n\n\nRows: 2,192\nColumns: 26\n$ file                          &lt;chr&gt; \"APAucará LD L001\", \"APAucará LD L001\", …\n$ identifier                    &lt;chr&gt; \"E001\", \"E002\", \"E003\", \"E004\", \"E005\", …\n$ event_type                    &lt;chr&gt; \"Entierro\", \"Entierro\", \"Entierro\", \"Ent…\n$ event_date                    &lt;date&gt; 1846-10-06, 1846-10-07, 1846-11-02, 184…\n$ doctrine                      &lt;chr&gt; \"Parroquia de Aucará\", \"Parroquia de Auc…\n$ event_place                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ deceased_name                 &lt;chr&gt; \"julian\", \"joce\", \"martina\", \"dorotea\", …\n$ deceased_lastname             &lt;chr&gt; \"xavies\", \"raime\", \"condori\", \"ccoyllo\",…\n$ deceased_birth_date           &lt;date&gt; NA, 1821-10-13, 1766-11-21, 1806-12-18,…\n$ deceased_birth_place          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ deceased_social_condition     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ deceased_marital_status       &lt;chr&gt; \"\\\"marido que fue\\\"\", \"\\\"marido que fue\\…\n$ deceased_legitimacy_status    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ father_name                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"jua…\n$ father_lastname               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"her…\n$ mother_name                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"cle…\n$ mother_lastname               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"man…\n$ husband_name                  &lt;chr&gt; NA, NA, \"luciano\", \"josé\", \"mariano\", \"g…\n$ wife_name                     &lt;chr&gt; \"mercedes\", \"francisca\", NA, NA, NA, NA,…\n$ burial_place                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ event_geographic_descriptor_1 &lt;chr&gt; \"Aucará\", \"Aucará\", \"Aucará\", \"Aucará\", …\n$ event_geographic_descriptor_2 &lt;chr&gt; \"Lucanas\", \"Lucanas\", \"Lucanas\", \"Lucana…\n$ event_geographic_descriptor_3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ event_geographic_descriptor_4 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ husband_lastname              &lt;chr&gt; NA, NA, \"ccoyllo\", \"espinosa\", \"huallpat…\n$ wife_lastname                 &lt;chr&gt; \"lupa\", \"cucho\", NA, NA, NA, NA, \"javier…\n\n\n\n\n\nThe burials table contains cleaned and standardized records of burial events extracted from parish registers. Each row represents a unique burial event with associated attributes such as date, location, and information about the deceased individual and their surviving family members.\n\n\n\n\n\n\n\n\nProperty\nExpected Type\nDescription\n\n\n\n\nfile\nText\nSource file name from which the record was extracted\n\n\nidentifier\nText\nSequential identifier for the burial event\n\n\nevent_type\nText\nType of event (Entierro)\n\n\nevent_date\nDate\nDate of the burial event in ISO 8601 format\n\n\ndoctrine\nText\nName of the parish or doctrine where the burial was registered\n\n\nevent_place\nText\nPlace where the burial event took place\n\n\ndeceased_name\nText\nNormalized first and middle name(s) of the deceased individual\n\n\ndeceased_lastname\nText\nNormalized or inferred surname(s) of the deceased individual\n\n\ndeceased_birth_date\nDate\nDate of birth of the deceased individual in ISO 8601 format\n\n\ndeceased_birth_place\nText\nPlace of birth of the deceased individual\n\n\ndeceased_social_condition\nText\nSocial, ethnical, or political marker of the deceased (mestizo, indio, tributario, vecino, don, doña)\n\n\ndeceased_marital_status\nText\nMarital status of the deceased at the time of death (soltero/soltera, casado/casada, viudo/viuda, marido que fue, mujer que fue)\n\n\ndeceased_legitimacy_status\nText\nLegitimacy status of the deceased at birth (legítimo, ilegitimo, natural)\n\n\nfather_name\nText\nNormalized name of the deceased’s father\n\n\nfather_lastname\nText\nNormalized or inferred surname(s) of the deceased’s father\n\n\nmother_name\nText\nNormalized name of the deceased’s mother\n\n\nmother_lastname\nText\nNormalized or inferred surname(s) of the deceased’s mother\n\n\nhusband_name\nText\nNormalized name of the deceased’s husband (when deceased was married)\n\n\nwife_name\nText\nNormalized name of the deceased’s wife (when deceased was married)\n\n\nburial_place\nText\nSpecific location where the deceased was buried\n\n\nevent_geographic_descriptor_1\nText\nPlace or location mentioned in the record\n\n\nevent_geographic_descriptor_2\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_3\nText\nAdditional place or location mentioned in the record\n\n\nevent_geographic_descriptor_4\nText\nAdditional place or location mentioned in the record\n\n\nhusband_lastname\nText\nNormalized or inferred surname(s) of the deceased’s husband\n\n\nwife_lastname\nText\nNormalized or inferred surname(s) of the deceased’s wife",
    "crumbs": [
      "Documentation",
      "Metadata Dictionary"
    ]
  },
  {
    "objectID": "docpages/metadata_dictionary.html#places",
    "href": "docpages/metadata_dictionary.html#places",
    "title": "Metadata Dictionary",
    "section": "Places",
    "text": "Places\nThe places table represents a controlled vocabulary of geographic locations extracted from all event records and normalized through a combination of manual curation and automated gazetteer matching. Each place has been geocoded and linked to external authorities (GeoNames, Getty Thesaurus of Geographic Names) when possible, enabling spatial analysis and visualization of the historical records.\n\n\n\n\n\n\nDataset Structure\n\n\n\n\n\n\n\nShow code\nplaces &lt;- readr::read_csv(\"../../data/clean/unique_places.csv\", show_col_types = FALSE)\nplaces %&gt;% glimpse()\n\n\nRows: 74\nColumns: 16\n$ place_id                  &lt;dbl&gt; 1, 4, 6, 8, 12, 13, 14, 15, 16, 17, 18, 19, …\n$ manually_normalized_place &lt;chr&gt; \"Acobamba\", \"Andamarca\", \"Apongo\", \"Aucará\",…\n$ standardize_label         &lt;chr&gt; \"Acobamba\", \"Andamarca\", \"Apongo\", \"Aucará\",…\n$ language                  &lt;chr&gt; \"es\", \"es\", \"es\", \"es\", \"es\", \"es\", \"es\", \"e…\n$ latitude                  &lt;dbl&gt; -12.07757, -15.63833, -14.01327, -14.25000, …\n$ longitude                 &lt;dbl&gt; -74.87127, -70.58848, -73.93247, -74.08333, …\n$ source                    &lt;chr&gt; \"GeoNames\", \"GeoNames\", \"GeoNames\", \"GeoName…\n$ id                        &lt;dbl&gt; 8663907, 3947725, 3947431, 3947087, 3939003,…\n$ uri                       &lt;chr&gt; \"http://sws.geonames.org/8663907/\", \"http://…\n$ country_code              &lt;chr&gt; \"PE\", \"PE\", \"PE\", \"PE\", \"PE\", \"PE\", \"PE\", \"P…\n$ part_of                   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ part_of_uri               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ confidence                &lt;dbl&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100,…\n$ threshold                 &lt;dbl&gt; 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, …\n$ match_type                &lt;chr&gt; \"exact\", \"exact\", \"exact\", \"exact\", \"exact\",…\n$ mentioned_as              &lt;chr&gt; \"['Acobamba']\", \"['Andamarca']\", \"['Apongo']…\n\n\n\n\n\nThe places table contains unique geographic locations mentioned in the parish records, along with their standardized names and geographic coordinates.\n\n\n\n\n\n\n\n\nProperty\nExpected Type\nDescription\n\n\n\n\nplace_id\nNumeric\nUnique identifier for the place\n\n\nmanually_normalized_name\nText\n\n\n\nstandardized_name\nText\nName standardized using external gazetteers\n\n\nlanguage\nText\nLanguage of the place name (e.g., es, en)\n\n\nlatitude\nNumeric\nLatitude coordinate of the place\n\n\nlongitude\nNumeric\nLongitude coordinate of the place\n\n\nsource_gazetteer\nText\nSource gazetteer used for standardization (e.g., geonames, tgn)\n\n\nid\nText\nIdentifier of the place in the source gazetteer\n\n\nuri\nText\nURI linking to the place in the source gazetteer\n\n\ncountry_code\nText\nISO country code of the place\n\n\npart_of\nText\nHigher-level administrative division the place belongs to\n\n\npart_of_uri\nText\nURI of the higher-level administrative division\n\n\nconfidence\nNumeric\nConfidence score of the place standardization (0-100)\n\n\ntreshold\nNumeric\nTreshold used for the place standardization\n\n\nmatch_type\nText\nType of match made during standardization (e.g., exact, fuzzy)\n\n\nmentioned_as\nText\nOriginal text mention of the place in the records",
    "crumbs": [
      "Documentation",
      "Metadata Dictionary"
    ]
  },
  {
    "objectID": "docpages/metadata_dictionary.html#personas",
    "href": "docpages/metadata_dictionary.html#personas",
    "title": "Metadata Dictionary",
    "section": "Personas",
    "text": "Personas\nPersonas represent individual person mentions extracted from all event records and restructured into a person-centric format. Unlike the event tables which are organized around ceremonies, this table focuses on individuals and their attributes as documented across multiple events. Each row is a unique person mention with inferred demographic information, though multiple mentions may refer to the same historical individual. Future work will link these mentions through probabilistic record linkage to reconstruct life histories.\n\n\n\n\n\n\nDataset Structure\n\n\n\n\n\n\n\nShow code\npersonas &lt;- readr::read_csv(\"../../data/clean/personas.csv\", show_col_types = FALSE)\npersonas %&gt;% glimpse()\n\n\nRows: 47,072\nColumns: 15\n$ event_idno          &lt;chr&gt; \"bautizo-1\", \"bautizo-1\", \"bautizo-1\", \"bautizo-1\"…\n$ original_identifier &lt;chr&gt; \"APAucará-LB-L001_B001\", \"APAucará-LB-L001_B001\", …\n$ persona_type        &lt;chr&gt; \"baptized\", \"father\", \"mother\", \"godfather\", \"bapt…\n$ name                &lt;chr&gt; \"domingo\", \"lucas\", \"sevastiana\", \"vicente\", \"domi…\n$ birth_place         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ birth_date          &lt;date&gt; 1790-08-04, NA, NA, NA, 1790-08-04, NA, NA, NA, 1…\n$ legitimacy_status   &lt;chr&gt; \"legitimo\", NA, NA, NA, \"legitimo\", NA, NA, NA, \"l…\n$ lastname            &lt;chr&gt; \"ayquipa\", \"ayquipa\", \"quispe\", \"guamani\", \"lulia\"…\n$ persona_idno        &lt;chr&gt; \"persona-1\", \"persona-2\", \"persona-3\", \"persona-4\"…\n$ social_condition    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ marital_status      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ resident_in         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ death_place         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ death_date          &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ gender              &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\", \"male\"…\n\n\n\n\n\nPersonas represent individual mentions of people in the historical records before any aggregation through probabilistic record linkage (PRL). Each row corresponds to a unique mention with associated attributes such as name, birth and death details, and places.\n\n\n\n\n\n\n\n\nProperty\nExpected Type\nDescription\n\n\n\n\nevent_idno\nText\nUnique identifier for the event mention\n\n\noriginal_identifier\nText\nOriginal identifier from the source document\n\n\nname\nText\nNormalized first and middle name(s)\n\n\nlastname\nText\nNormalized or inferred surname(s)\n\n\npersona_type\nText\nType of persona (e.g., baptized, parent, godparent)\n\n\nbirth_date\nDate\nRecorded or inferred date of birth in ISO 8601 format\n\n\nbirth_place\nText\nPlace of birth\n\n\ndeath_date\nDate\nRecorded or inferred date of death in ISO 8601 format\n\n\ndeath_place\nText\nPlace of death\n\n\ngender\nText\nInferred gender (male, female, unknown)\n\n\nresident_in\nText\nRecorded place of residence at the time of the event\n\n\nlegitimacy_status\nText\nLegitimacy status at birth (legitimo, ilegitimo)\n\n\nmarital_status\nText\nMarital status at the time of the event (soltero, casado)\n\n\nsocial_condition\nText\nSocial, ethnical, or political marker (mestizo, indio, tributario, vecino)",
    "crumbs": [
      "Documentation",
      "Metadata Dictionary"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This project employs probabilistic record linkage methods to identify unique individuals within parish records from the Sondondo Valley, Peru, spanning from 1760 to 1921. The collection encompasses 10,180 historical records across three vital event types: baptisms (6,340 records), marriages (1,719 records), and burials (2,121 records).\nHistorical parish records provide valuable insights into demographic, social, and familial patterns, but they often lack explicit unique identifiers, making it challenging to track individuals across multiple life events. By leveraging contextual data—such as names, familial relationships, geographic locations, and event dates—this project aims to reconstruct individual life histories and reveal the social networks of this historical community.\n\n\n\nEntity Resolution: Apply probabilistic record linkage to identify unique individuals across multiple event records\nData Standardization: Clean, normalize, and harmonize inconsistent historical data from manuscript sources\nNetwork Analysis: Uncover familial and social connections within the community through relationship mapping\nMethodological Contribution: Develop replicable workflows for processing historical datasets with similar challenges\n\n\n\n\n\nThis documentation site presents the complete data processing pipeline through a series of interconnected notebooks and reference materials:\n\n\nThe Notebooks section contains detailed computational workflows documenting each phase of data processing:\n\nData Cleaning: Comprehensive data cleaning including column harmonization, date normalization, name standardization, and quality validation\nPlace Mapping: Geographic entity extraction using Named Entity Recognition (NER) and standardization through external gazetteers\nTextual Variation Analysis: Statistical analysis of social condition terminology and controlled vocabulary development\nPersonas Creation: Extraction and consolidation of individual person mentions from event records into a unified person-centric dataset\nVisualizations: Exploratory data analysis and visual summaries of the processed datasets\n\n\n\n\nThe Documentation section provides reference materials for understanding and working with the datasets:\n\nMetadata Dictionary: Complete field-level documentation for all cleaned datasets, including data types, descriptions, and controlled vocabularies\n\n\n\n\n\nPhase: ✅ Data Cleaning & Personas Creation Complete\nThe project has successfully completed initial data collection, comprehensive cleaning and standardization, and the creation of a unified personas dataset. Current work focuses on implementing probabilistic record linkage algorithms to identify unique individuals across the corpus.\n\n\n\nData was collected through manual transcription from digitized parish registers of the Sondondo Valley, Peru. All transcriptions were performed directly from document images using structured templates in Google Sheets, followed by manual review for quality assurance.\n\nFor technical details, source code, and raw data access, visit the project repository.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#project-overview",
    "href": "index.html#project-overview",
    "title": "Welcome",
    "section": "",
    "text": "This project employs probabilistic record linkage methods to identify unique individuals within parish records from the Sondondo Valley, Peru, spanning from 1760 to 1921. The collection encompasses 10,180 historical records across three vital event types: baptisms (6,340 records), marriages (1,719 records), and burials (2,121 records).\nHistorical parish records provide valuable insights into demographic, social, and familial patterns, but they often lack explicit unique identifiers, making it challenging to track individuals across multiple life events. By leveraging contextual data—such as names, familial relationships, geographic locations, and event dates—this project aims to reconstruct individual life histories and reveal the social networks of this historical community.\n\n\n\nEntity Resolution: Apply probabilistic record linkage to identify unique individuals across multiple event records\nData Standardization: Clean, normalize, and harmonize inconsistent historical data from manuscript sources\nNetwork Analysis: Uncover familial and social connections within the community through relationship mapping\nMethodological Contribution: Develop replicable workflows for processing historical datasets with similar challenges",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#documentation-structure",
    "href": "index.html#documentation-structure",
    "title": "Welcome",
    "section": "",
    "text": "This documentation site presents the complete data processing pipeline through a series of interconnected notebooks and reference materials:\n\n\nThe Notebooks section contains detailed computational workflows documenting each phase of data processing:\n\nData Cleaning: Comprehensive data cleaning including column harmonization, date normalization, name standardization, and quality validation\nPlace Mapping: Geographic entity extraction using Named Entity Recognition (NER) and standardization through external gazetteers\nTextual Variation Analysis: Statistical analysis of social condition terminology and controlled vocabulary development\nPersonas Creation: Extraction and consolidation of individual person mentions from event records into a unified person-centric dataset\nVisualizations: Exploratory data analysis and visual summaries of the processed datasets\n\n\n\n\nThe Documentation section provides reference materials for understanding and working with the datasets:\n\nMetadata Dictionary: Complete field-level documentation for all cleaned datasets, including data types, descriptions, and controlled vocabularies",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#current-status",
    "href": "index.html#current-status",
    "title": "Welcome",
    "section": "",
    "text": "Phase: ✅ Data Cleaning & Personas Creation Complete\nThe project has successfully completed initial data collection, comprehensive cleaning and standardization, and the creation of a unified personas dataset. Current work focuses on implementing probabilistic record linkage algorithms to identify unique individuals across the corpus.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#data-sources",
    "href": "index.html#data-sources",
    "title": "Welcome",
    "section": "",
    "text": "Data was collected through manual transcription from digitized parish registers of the Sondondo Valley, Peru. All transcriptions were performed directly from document images using structured templates in Google Sheets, followed by manual review for quality assurance.\n\nFor technical details, source code, and raw data access, visit the project repository.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "2_placeMapping.html",
    "href": "2_placeMapping.html",
    "title": "Place Name Normalization",
    "section": "",
    "text": "The resulting dataset (data/clean/unique_places.csv) serves as the authoritative lookup table for all place references across the project, enabling consistent spatial analysis and record linkage.\nHistorical documents present significant challenges in place name identification due to spelling variations, ambiguous toponyms, and evolving geographic nomenclature. This notebook establishes an authoritative gazetteer of unique places mentioned in the Sondondo sacramental records through a two-phase approach:",
    "crumbs": [
      "Notebooks",
      "Place Mapping"
    ]
  },
  {
    "objectID": "2_placeMapping.html#data-preparation",
    "href": "2_placeMapping.html#data-preparation",
    "title": "Place Name Normalization",
    "section": "Data Preparation",
    "text": "Data Preparation\nWe begin by loading the cleaned sacramental records, which have already undergone date normalization and attribute harmonization. Place names at this stage retain their original spelling variations as recorded in the historical documents.\n\nimport pandas as pd\n\n\nPLACES_MAP = '../data/mappings/places_types.json'\n\n\nBAUTISMOS_HARMONIZED = pd.read_csv(\"../data/clean/bautismos_clean.csv\")\nMATRIMONIOS_HARMONIZED = pd.read_csv(\"../data/clean/matrimonios_clean.csv\")\nENTIERROS_HARMONIZED = pd.read_csv(\"../data/clean/entierros_clean.csv\")\n\nBAUTISMOS_HARMONIZED\n\n\n\n\n\n\n\n\nfile\nidentifier\nevent_type\nevent_date\nbaptized_name\nbaptized_birth_place\nbaptized_birth_date\nbaptized_legitimacy_status\nfather_name\nfather_lastname\n...\ngodfather_social_condition\ngodmother_name\ngodmother_lastname\ngodmother_social_condition\nevent_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\nbaptized_lastname\n\n\n\n\n0\nAPAucará LB L001\nB001\nBautizo\n1790-10-04\ndomingo\nNaN\n1790-08-04\nHijo legitimo\nlucas\nayquipa\n...\nNaN\nNaN\nNaN\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\nayquipa\n\n\n1\nAPAucará LB L001\nB002\nBautizo\n1790-10-06\ndominga\nNaN\n1790-08-04\nHija legitima\njuan\nlulia\n...\nNaN\nNaN\nNaN\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\nlulia\n\n\n2\nAPAucará LB L001\nB003\nBautizo\n1790-10-07\nbartola\nNaN\n1790-08-04\nHija legitima\njacinto\nquispe\n...\nNaN\nrotonda\npocco\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\nquispe\n\n\n3\nAPAucará LB L001\nB004\nBautizo\n1790-10-20\nfrancisca\nNaN\n1790-10-15\nHija legitima\njuan\ncuebas\n...\nNaN\nysabel\nguillen\nNaN\nAucara\nAucara\nNaN\nNaN\nNaN\ncuebas\n\n\n4\nAPAucará LB L001\nB005\nBautizo\n1790-10-20\npedro\nNaN\n1790-10-19\nHijo legitimo\nsantos\nmanxo\n...\nNaN\njosefa\nsantiago\nNaN\nAucara\nAucara\nNaN\nNaN\nNaN\nmanxo\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6335\nAPAucará LB L004\nB2042\nBautizo\n1888-12-10\nleocadio\nNaN\n1888-12-09\nHijo natural, mestizo\nmiguel\npacheco\n...\nNaN\nNaN\nNaN\nNaN\nAucará\nAucará\nAucará\nNaN\nNaN\npacheco\n\n\n6336\nAPAucará LB L004\nB2043\nBautizo\n1888-12-11\nmariano concepcion\nNaN\n1888-12-07\nHijo legítimo, indio\nfacundo\nvega\n...\nNaN\nNaN\nNaN\nNaN\nAucará\nAucará\nAucará\nNaN\nNaN\nvega\n\n\n6337\nAPAucará LB L004\nB2044\nBautizo\n1888-12-12\nambrosio\nNaN\n1888-12-06\nHijo legítimo, indio\nysidro\nccasane\n...\nNaN\nNaN\nNaN\nNaN\nAucará\nAucará\nMayobamba\nNaN\nNaN\nccasane\n\n\n6338\nAPAucará LB L004\nB2045\nBautizo\n1888-12-15\nfrancisco\nNaN\n1888-11-30\nHijo legítimo, indio\nmariano\nlopez\n...\nIndigna de Huaicahuacho\nNaN\nNaN\nNaN\nAucará\nAucará\nHuaicahuacho\nNaN\nNaN\nlopez\n\n\n6339\nAPAucará LB L004\nB2046\nBautizo\n1888-12-16\nlaureana\nNaN\n1888-12-01\nHija legítima, india\nbernarda\nchampa\n...\nNaN\nmanuela\nde la cruz\nNaN\nAucará\nAucará\nChacralla\nNaN\nNaN\nchampa\n\n\n\n\n6340 rows × 27 columns",
    "crumbs": [
      "Notebooks",
      "Place Mapping"
    ]
  },
  {
    "objectID": "2_placeMapping.html#automated-place-extraction",
    "href": "2_placeMapping.html#automated-place-extraction",
    "title": "Place Name Normalization",
    "section": "Automated Place Extraction",
    "text": "Automated Place Extraction\nThe PlaceExtractor identifies place mentions within text fields and applies initial normalization using the geographic type taxonomy defined in places_types.json. This automated process handles straightforward cases but requires manual review for ambiguous toponyms.\nWe systematically process all place-related columns across the three sacramental record types, applying the extractor to standardize formatting and identify geographic descriptors.\n\nExtract Place Mentions\n\nfrom actions.extractors import placeRecognition\n\nextractor = placeRecognition.PlaceExtractor()\n\n\nBaptismal Records\n\nbautismos_place_columns = [\n    'baptized_birth_place', 'event_place', 'event_geographic_descriptor_1',\n        'event_geographic_descriptor_2', 'event_geographic_descriptor_3',\n        'event_geographic_descriptor_4'\n]\n\nfor col in bautismos_place_columns:\n    if col in BAUTISMOS_HARMONIZED.columns:\n        BAUTISMOS_HARMONIZED[col] = extractor.extract_places_per_row(BAUTISMOS_HARMONIZED[col])\n\nBAUTISMOS_HARMONIZED[bautismos_place_columns]\n\n\n\n\n\n\n\n\nbaptized_birth_place\nevent_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\n\n\n\n\n0\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\n\n\n1\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\n\n\n2\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\n\n\n3\nNaN\nAucara\nAucara\nNaN\nNaN\nNaN\n\n\n4\nNaN\nAucara\nAucara\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n6335\nNaN\nAucará\nAucará\nAucará\nNaN\nNaN\n\n\n6336\nNaN\nAucará\nAucará\nAucará\nNaN\nNaN\n\n\n6337\nNaN\nAucará\nAucará\nMayobamba\nNaN\nNaN\n\n\n6338\nNaN\nAucará\nAucará\nHuaicahuacho\nNaN\nNaN\n\n\n6339\nNaN\nAucará\nAucará\nChacralla\nNaN\nNaN\n\n\n\n\n6340 rows × 6 columns\n\n\n\n\n\nMarriage Records\n\nmatrimonios_place_columns = [\n    'husband_birth_place',\n       'husband_resident_in', \n       'wife_birth_place', 'wife_resident_in', \n       'event_place', 'event_geographic_descriptor_1', 'event_geographic_descriptor_2',\n       'event_geographic_descriptor_3', 'event_geographic_descriptor_4',\n       'event_geographic_descriptor_5', 'event_geographic_descriptor_6'\n]\n\nfor col in matrimonios_place_columns:\n    if col in MATRIMONIOS_HARMONIZED.columns:\n        MATRIMONIOS_HARMONIZED[col] = extractor.extract_places_per_row(MATRIMONIOS_HARMONIZED[col])\n\nMATRIMONIOS_HARMONIZED[matrimonios_place_columns]\n\n\n\n\n\n\n\n\nhusband_birth_place\nhusband_resident_in\nwife_birth_place\nwife_resident_in\nevent_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\nevent_geographic_descriptor_5\nevent_geographic_descriptor_6\n\n\n\n\n0\nCiudad de Huamanga\nAucara\nNaN\nNaN\nAucara\nAucara\nHuamanga\nCoracora\nNaN\nNaN\nNaN\n\n\n1\nNaN\nNaN\nNaN\nNaN\nAucara\nAucara\nColca\nNaN\nNaN\nNaN\nNaN\n\n\n2\nPampamarca\nNaN\nPampamarca\nNaN\nAucara\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n3\nPampamarca\nNaN\nPampamarca\nNaN\nPampamarca|santa iglesia\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n4\nNaN\nNaN\nNaN\nNaN\nPampamarca|santa iglesia\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1714\nPampamarca\nNaN\nPampamarca\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n1715\nChacralla\nNaN\nChacralla\nNaN\nChacralla, iglesia vice-parroquial\nAucara\nChacralla\nNaN\nNaN\nNaN\nNaN\n\n\n1716\nChacralla\nNaN\nChacralla\nNaN\nChacralla, iglesia vice-parroquial\nAucara\nChacralla\nNaN\nNaN\nNaN\nNaN\n\n\n1717\nNaN\nAucara\nNaN\nAucara\nAucara\nAucara\nQueca\nNaN\nNaN\nNaN\nNaN\n\n\n1718\nPampamarca\nNaN\nPampamarca\nNaN\nPampamarca\nAucara\nPampamarca\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n1719 rows × 11 columns\n\n\n\n\n\nBurial Records\n\nentierros_place_columns = [\n    'event_place', 'deceased_birth_place', 'burial_place', 'event_geographic_descriptor_1',\n    'event_geographic_descriptor_2', 'event_geographic_descriptor_3',\n    'event_geographic_descriptor_4'\n]\n\nfor col in entierros_place_columns:\n    if col in ENTIERROS_HARMONIZED.columns:\n        ENTIERROS_HARMONIZED[col] = extractor.extract_places_per_row(ENTIERROS_HARMONIZED[col])\n\nENTIERROS_HARMONIZED[entierros_place_columns]\n\n\n\n\n\n\n\n\nevent_place\ndeceased_birth_place\nburial_place\nevent_geographic_descriptor_1\nevent_geographic_descriptor_2\nevent_geographic_descriptor_3\nevent_geographic_descriptor_4\n\n\n\n\n0\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n1\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n3\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n4\nNaN\nNaN\nNaN\nAucará\nLucanas\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2187\nAucara\nSanta Ana de Aucara\nNaN\nAucara\nSanta Ana de Aucara\nNaN\nNaN\n\n\n2188\nAucara\nPampamarca\nNaN\nAucara\nPampamarca\nNaN\nNaN\n\n\n2189\nAucara\nSanta Ana de Aucara\nNaN\nAucara\nSanta Ana de Aucara\nNaN\nNaN\n\n\n2190\nAucara\nAucara\nNaN\nAucara\nNaN\nNaN\nNaN\n\n\n2191\nAucara\nAucara\nNaN\nAucara\nNaN\nNaN\nNaN\n\n\n\n\n2192 rows × 7 columns\n\n\n\n\n\n\nConsolidate and Resolve Places\nThe MapPlaces class aggregates all place mentions from the three datasets, identifies unique toponyms, and attempts automated resolution against authoritative gazetteers. The output is suppressed here as it produces verbose logging; results are saved for subsequent manual review.\n\n%%capture\n\nbautismos_places = BAUTISMOS_HARMONIZED[bautismos_place_columns]\nmatrimonios_places = MATRIMONIOS_HARMONIZED[matrimonios_place_columns] \nentierros_places = ENTIERROS_HARMONIZED[entierros_place_columns]\n\nmap_places = placeRecognition.MapPlaces([bautismos_places, matrimonios_places, entierros_places], places_map=PLACES_MAP)\nall_unique_places = map_places.resolve_places()\nprint(\"All unique places extracted:\")\nprint(all_unique_places)\n\n\nall_unique_places.to_csv(\"../data/interim/unique_places.csv\", index=False)\n\n\nstandardized_places = all_unique_places.loc[all_unique_places['uri'].notna()]\nstandardized_places.groupby('uri').first().reset_index().sort_values(by='standardize_label').to_csv(\"../data/interim/standardized_places.csv\", index=False)",
    "crumbs": [
      "Notebooks",
      "Place Mapping"
    ]
  },
  {
    "objectID": "2_placeMapping.html#manual-curation-and-authority-control",
    "href": "2_placeMapping.html#manual-curation-and-authority-control",
    "title": "Place Name Normalization",
    "section": "Manual Curation and Authority Control",
    "text": "Manual Curation and Authority Control\nAutomated place resolution, while effective for unambiguous cases, cannot handle toponymic challenges such as:\n\nHomonyms: Multiple places sharing the same name (e.g., “Pampamarca” appears in multiple regions)\nHistorical name changes: Places known by different names across time periods\nSpelling variations: Inconsistent orthography in colonial records (e.g., “Ishua” vs “Ischua”)\nAmbiguous references: Generic descriptors that could refer to multiple locations\n\nTo address these issues, we created data/interim/unique_places_manual.csv, an authority file that maps variant forms (mentioned_as) to canonical place names with verified geographic coordinates and gazetteer identifiers.\n\nValidation Against Manual Normalization\nWe compare the automated extraction results against the manually curated authority file to identify discrepancies and ensure completeness.\n\nuplaces = pd.read_csv('../data/interim/unique_places_manual.csv')\nset_diff = set(standardized_places['standardize_label']) - set(uplaces['manually_normalized_place'])\n\n\nset_diff\n\n{'Cachihuancaray',\n 'Carhuanca',\n 'Carlos Fitzcarrald',\n 'Ceibo Roto',\n 'Champa',\n 'Chaupicancha',\n 'Chipao',\n 'Chuschi',\n 'Ciudad Libertad de las Américas',\n 'Cochas',\n 'Collay',\n 'Coracora',\n 'Dos de Mayo',\n 'Huambo',\n 'Huanacopampa',\n 'Huancapi',\n 'Huancaraylla',\n 'Illapata',\n 'India Muerta',\n 'Indio Piro',\n 'Julca',\n 'Llusita',\n 'Marca',\n 'Paico',\n 'Paire',\n 'Palco',\n 'Pausa',\n 'Pincocalla',\n 'Poma Patacollo',\n 'Queca',\n 'Querco',\n 'San Pedro de Lloc',\n 'Santa Anita - Los Ficus',\n 'Santa Iglesia',\n 'Santa María',\n 'Taulli',\n 'Yanaccollpa'}\n\n\n\n\nAuthoritative Place Resolution\nThe AuthoritativePlaceResolver applies the manually curated authority file to resolve all place mentions. For each canonical place name, it queries multiple authoritative gazetteers in priority order:\n\nGeoNames - comprehensive global gazetteer with detailed administrative hierarchies\nGetty Thesaurus of Geographic Names (TGN) - art historical geographic authority\nWorld Historical Gazetteer (WHG) - specialized in historical place names\nWikidata - linked data resource with extensive geographic coverage\n\nThis process produces data/clean/unique_places.csv, the authoritative lookup table linking historical place mentions to verified geographic entities with coordinates, hierarchical context, and stable identifiers.\nNote: We extended places_types.json to include “administrative division” as a recognized geographic type, enabling better classification of jurisdictional references in the historical records:\n\"administrative division\": {\n    \"geonames\": \"A\",\n    \"wikidata\": \"Q5\",\n    \"tgn\": \"administrative divisions\",\n    \"whg\": \"a\"\n  }\n\n%%capture\n\nmanual_data = pd.read_csv('../data/interim/unique_places_manual.csv')\n\nresolver = placeRecognition.AuthoritativePlaceResolver(data=manual_data, places_map=PLACES_MAP)\nresult_df = resolver.resolve_places()\n\nprint(\"Resolved places:\")\nprint(result_df)",
    "crumbs": [
      "Notebooks",
      "Place Mapping"
    ]
  },
  {
    "objectID": "2_placeMapping.html#database-integration",
    "href": "2_placeMapping.html#database-integration",
    "title": "Place Name Normalization",
    "section": "Database Integration",
    "text": "Database Integration\nTo prepare the gazetteer for relational database storage, we assign a unique integer identifier (place_id) to each canonical place. This serves as the primary key in the places table and enables efficient joins with sacramental records.\n\nresult_df['place_id'] = result_df.index + 1\nresult_df = result_df.set_index('place_id')\n\nresult_df\n\n\n\n\n\n\n\n\nmanually_normalized_place\nstandardize_label\nlanguage\nlatitude\nlongitude\nsource\nid\nuri\ncountry_code\npart_of\npart_of_uri\nconfidence\nthreshold\nmatch_type\nmentioned_as\n\n\nplace_id\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nAcobamba\nAcobamba\nes\n-12.07757\n-74.87127\nGeoNames\n8663907.0\nhttp://sws.geonames.org/8663907/\nPE\n\n\n100.0\n90.0\nexact\n[Acobamba]\n\n\n4\nAndamarca\nAndamarca\nes\n-15.63833\n-70.58848\nGeoNames\n3947725.0\nhttp://sws.geonames.org/3947725/\nPE\n\n\n100.0\n90.0\nexact\n[Andamarca]\n\n\n6\nApongo\nApongo\nes\n-14.01327\n-73.93247\nGeoNames\n3947431.0\nhttp://sws.geonames.org/3947431/\nPE\n\n\n100.0\n90.0\nexact\n[Apongo]\n\n\n8\nAucará\nAucará\nes\n-14.25000\n-74.08333\nGeoNames\n3947087.0\nhttp://sws.geonames.org/3947087/\nPE\n\n\n100.0\n90.0\nexact\n[Aucara, Aucara Barrio de Mayo, Aucará, Barrio...\n\n\n12\nHuaycahuaycho\nHuaycahuaycho\nes\n-14.15000\n-74.01667\nGeoNames\n3939003.0\nhttp://sws.geonames.org/3939003/\nPE\n\n\n100.0\n90.0\nexact\n[Aucara Huaycahuacho, Huaicahuacho]\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n85\nSoras Pata\nSoras Pata\nes\n-14.23741\n-70.65011\nGeoNames\n13238703.0\nhttp://sws.geonames.org/13238703/\nPE\n\n\n100.0\n90.0\nexact\n[Soras]\n\n\n87\nUmasi\nUmasi\nes\n-14.89142\n-70.68701\nGeoNames\n13238711.0\nhttp://sws.geonames.org/13238711/\nPE\n\n\n100.0\n90.0\nexact\n[Umaci, Umasi]\n\n\n88\nUrubamba\nUrubamba\nes\n-13.30472\n-72.11583\nGeoNames\n3926438.0\nhttp://sws.geonames.org/3926438/\nPE\n\n\n100.0\n90.0\nexact\n[Urabamba]\n\n\n89\nVilcashuamán\nVilcashuamán\nes\n-13.65361\n-73.95306\nGeoNames\n3926141.0\nhttp://sws.geonames.org/3926141/\nPE\n\n\n100.0\n90.0\nexact\n[Vilcas]\n\n\n90\nVilla San Juan\nVilla San Juan\nes\n-6.37252\n-79.80292\nGeoNames\n3820188.0\nhttp://sws.geonames.org/3820188/\nPE\n\n\n100.0\n90.0\nexact\n[Villa de San Juan]\n\n\n\n\n74 rows × 15 columns\n\n\n\n\nresult_df.to_csv(\"../data/clean/unique_places.csv\", index=True)",
    "crumbs": [
      "Notebooks",
      "Place Mapping"
    ]
  },
  {
    "objectID": "2_placeMapping.html#summary",
    "href": "2_placeMapping.html#summary",
    "title": "Place Name Normalization",
    "section": "Summary",
    "text": "Summary\nThis notebook established an authoritative gazetteer for the Sondondo sacramental records through a two-phase normalization process:\n\nAutomated extraction identified place mentions across all three sacramental record types\nManual curation resolved ambiguous toponyms and linked canonical forms to authoritative geographic databases\nAuthority control produced a verified lookup table with stable identifiers and coordinates\n\nThe resulting dataset (data/clean/unique_places.csv) provides:\n\nControlled vocabulary for place names, reducing spelling variations\nGeographic coordinates enabling spatial analysis\nLinks to authoritative gazetteers (GeoNames, TGN, WHG, Wikidata) for interoperability\nHierarchical geographic context (administrative divisions, place types)\nStable identifiers for database integration\n\nThis gazetteer is essential for subsequent analyses involving geographic mobility, spatial clustering, and linking records across events.",
    "crumbs": [
      "Notebooks",
      "Place Mapping"
    ]
  },
  {
    "objectID": "4_personasCreation.html",
    "href": "4_personasCreation.html",
    "title": "Personas Creation",
    "section": "",
    "text": "Our approach aligns closely with the input preparation model proposed by David W. Embley (2021). We structure our data around personas, defined as “each mention instance of a person in a document” (p. 66), as a foundational step toward probabilistic record linkage (PRL). Each persona is created by ingesting available individual metadata (such as name, last name, birth date), associating the person with a sacramental event (baptism, marriage, or burial). The relationship between personas is established by their participation at the event (e.g., as father, mother, godfather, witness).",
    "crumbs": [
      "Notebooks",
      "Personas Creation"
    ]
  },
  {
    "objectID": "4_personasCreation.html#personas-data-structure",
    "href": "4_personasCreation.html#personas-data-structure",
    "title": "Personas Creation",
    "section": "Personas Data Structure",
    "text": "Personas Data Structure\nThe personas data structure is very straightforward:\n\nevent_idno: unique semantically meaningful identifier for the event\npersona_idno: unique semantically meaningful identifier for the persona\npersona_type: role of the persona in the event (e.g., baptized, father, mother, witness)\nname: first name of the persona\nlast_name: last name of the persona\nbirth_date: birth date of the persona\nbirth_place: birth place of the persona\nresident_in: persona residence at the time of the event\ngender: inferred gender of the persona\nsocial_condition: harmonized social condition of the persona\nlegitimacy_status: harmonized legitimacy status of the persona\nmarital_status: harmonized marital status of the persona\n\nIdentification of individuals is done by parsing one or a list of dataframes with the clean data, and processing the data using the Persona class. Results are stored in data/interim/personas_extracted.csv for testing, and in data/clean/personas.csv for production.",
    "crumbs": [
      "Notebooks",
      "Personas Creation"
    ]
  },
  {
    "objectID": "4_personasCreation.html#data-extraction",
    "href": "4_personasCreation.html#data-extraction",
    "title": "Personas Creation",
    "section": "Data Extraction",
    "text": "Data Extraction\nWe begin by loading the cleaned sacramental records and extracting persona instances using the PersonaExtractor class. This process creates individual persona records for each person mentioned in the historical documents, preserving their role in each event.\n\nimport pandas as pd\nfrom actions.extractors import Persona\n\n\nbautismos = pd.read_csv(\"../data/clean/bautismos_clean.csv\")\nentierros = pd.read_csv(\"../data/clean/entierros_clean.csv\")\nmatrimonios = pd.read_csv(\"../data/clean/matrimonios_clean.csv\")\n\n\nextractor = Persona.PersonaExtractor([bautismos, matrimonios, entierros])\npersonas = extractor.extract_personas()\n\npersonas.describe(include='all')\n\n\n\n\n\n\n\n\nevent_idno\noriginal_identifier\npersona_type\nname\nbirth_place\nbirth_date\nlegitimacy_status\nlastname\npersona_idno\nsocial_condition\nmarital_status\nresident_in\ndeath_place\ndeath_date\ngender\n\n\n\n\ncount\n47072\n47072\n47072\n46999\n5378\n8596\n11866\n46762\n47072\n9643\n4275\n925\n1513\n2114\n47072\n\n\nunique\n10180\n10179\n14\n4286\n53\n7001\n2\n2616\n47072\n7\n3\n19\n7\n1813\n6\n\n\ntop\nmatrimonio-490\nAPAucará-LM-L001_M490\nmother\nmariano\npampamarca\n1901-09-04\nlegitimo\nquispe\npersona-1\nindio\nsoltero\npampamarca\naucará\n1871-11-04\nmale\n\n\nfreq\n12\n12\n7614\n1556\n1919\n8\n9104\n2712\n1\n5654\n2779\n292\n1016\n7\n20150\n\n\n\n\n\n\n\n\nInitial Exploration\nBefore conducting detailed quality assessment, we examine the basic structure and distribution of persona types in the extracted dataset.\n\npersonas.to_csv(\"../data/clean/personas.csv\", index=False)\n\n\npersonas.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 47072 entries, 0 to 47071\nData columns (total 15 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   event_idno           47072 non-null  object\n 1   original_identifier  47072 non-null  object\n 2   persona_type         47072 non-null  object\n 3   name                 46999 non-null  object\n 4   birth_place          5378 non-null   object\n 5   birth_date           8596 non-null   object\n 6   legitimacy_status    11866 non-null  object\n 7   lastname             46762 non-null  object\n 8   persona_idno         47072 non-null  object\n 9   social_condition     9643 non-null   object\n 10  marital_status       4275 non-null   object\n 11  resident_in          925 non-null    object\n 12  death_place          1513 non-null   object\n 13  death_date           2114 non-null   object\n 14  gender               47072 non-null  object\ndtypes: object(15)\nmemory usage: 5.4+ MB",
    "crumbs": [
      "Notebooks",
      "Personas Creation"
    ]
  },
  {
    "objectID": "4_personasCreation.html#quality-assessment",
    "href": "4_personasCreation.html#quality-assessment",
    "title": "Personas Creation",
    "section": "Quality Assessment",
    "text": "Quality Assessment\nTo evaluate the suitability of the extracted personas for probabilistic record linkage, we assess data completeness across multiple dimensions: names, parental linkages, temporal information, spatial attributes, and social/legal status markers.\nNames are critical identifiers for record linkage. We assess the completeness of both first names and surnames across all persona types.\n\nName Completeness\n\nname_completeness = personas.loc[(personas['name'].isna()) | (personas['lastname'].isna())]\nname_completeness.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 383 entries, 62 to 46928\nData columns (total 15 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   event_idno           383 non-null    object\n 1   original_identifier  383 non-null    object\n 2   persona_type         383 non-null    object\n 3   name                 310 non-null    object\n 4   birth_place          35 non-null     object\n 5   birth_date           52 non-null     object\n 6   legitimacy_status    41 non-null     object\n 7   lastname             73 non-null     object\n 8   persona_idno         383 non-null    object\n 9   social_condition     55 non-null     object\n 10  marital_status       20 non-null     object\n 11  resident_in          0 non-null      object\n 12  death_place          26 non-null     object\n 13  death_date           53 non-null     object\n 14  gender               383 non-null    object\ndtypes: object(15)\nmemory usage: 47.9+ KB\n\n\n\nname_completeness['persona_type'].value_counts()\n\npersona_type\nmother               83\ndeceased             53\nfather_of_husband    45\nfather_of_wife       45\nfather               44\ngodmother            27\ngodfather            25\ngodparent            13\nwife                 13\nwitness              10\nhusband               9\nmother_of_wife        7\nmother_of_husband     5\nbaptized              4\nName: count, dtype: int64\n\n\n\n# Percentage of missing names\ntotal_personas = len(personas)\nmissing_names = len(name_completeness)\npercentage_missing_names = (missing_names / total_personas) * 100\nprint(f\"Percentage of personas with missing names: {percentage_missing_names:.2f}%\")\n\nPercentage of personas with missing names: 0.81%\n\n\n\nmissing_firstnames = personas.loc[personas['name'].isna()]\npercentage_missing_firstnames = (len(missing_firstnames) / total_personas) * 100\nprint(f\"Percentage of personas with missing firstnames: {percentage_missing_firstnames:.2f}%\")\n\nPercentage of personas with missing firstnames: 0.16%\n\n\n\nmissing_surnames = personas.loc[personas['lastname'].isna()]\npercentage_missing_surnames = (len(missing_surnames) / total_personas) * 100\nprint(f\"Percentage of personas with missing lastnames: {percentage_missing_surnames:.2f}%\")\n\nPercentage of personas with missing lastnames: 0.66%\n\n\n\n\nParental Linkage Completeness\nFor personas identified as children (baptized, deceased children, etc.), we assess whether their parents are properly linked in the dataset. The expectation differs by legitimacy status: legitimate children should have both parents recorded, while illegitimate children require at least one parent.\n\nlegitimate_sons = personas.loc[personas['legitimacy_status'] == 'legitimo']\nilegitimate_sons = personas.loc[personas['legitimacy_status'] == 'ilegitimo']\n\nsons_types = legitimate_sons['persona_type'].unique().tolist()\n\n# filter ilegitimate sons by sons types to avoid including other ilegitimate personas\nilegitimate_sons = ilegitimate_sons.loc[ilegitimate_sons['persona_type'].isin(sons_types)]\n\nprint(\"Legitimate Sons Persona Types and Counts:\")\nprint(legitimate_sons['persona_type'].value_counts())\nprint(\"\\nIlegitimate Sons Persona Types and Counts:\")\nprint(ilegitimate_sons['persona_type'].value_counts())\n\nLegitimate Sons Persona Types and Counts:\npersona_type\nbaptized    5483\nwife        1267\nhusband     1248\ndeceased    1106\nName: count, dtype: int64\n\nIlegitimate Sons Persona Types and Counts:\npersona_type\nbaptized    810\ndeceased    201\nwife        170\nhusband     165\nName: count, dtype: int64\n\n\n\ndef check_parents_completeness(sons_df, personas_df, legitimacy='leg'):\n    # Get unique event_idno from sons\n    event_ids = sons_df['event_idno'].unique()\n    \n    # Filter personas to only relevant events\n    relevant_personas = personas_df[personas_df['event_idno'].isin(event_ids)]\n    \n    # Check for father and mother presence by event\n    events_with_father = set(relevant_personas[relevant_personas['persona_type'].str.contains('father', na=False)]['event_idno'])\n    events_with_mother = set(relevant_personas[relevant_personas['persona_type'].str.contains('mother', na=False)]['event_idno'])\n    \n    if legitimacy == 'leg':\n        # For legitimate sons, both parents should be present\n        # Incomplete if missing father OR missing mother\n        events_missing_father = set(event_ids) - events_with_father\n        events_missing_mother = set(event_ids) - events_with_mother\n        incomplete_events = events_missing_father | events_missing_mother\n    elif legitimacy == 'ileg':\n        # For illegitimate sons, at least one parent should be present\n        # Incomplete if missing BOTH father AND mother\n        incomplete_events = set(event_ids) - events_with_father - events_with_mother\n    else:\n        raise ValueError(\"Legitimacy must be 'leg' or 'ileg'\")\n    \n    # Get sons with incomplete parents\n    incomplete_sons = sons_df[sons_df['event_idno'].isin(incomplete_events)]\n    return incomplete_sons\n\nincomplete_legit_parents = check_parents_completeness(legitimate_sons, personas)\nincomplete_ilegit_parents = check_parents_completeness(ilegitimate_sons, personas, legitimacy='ileg')\n\nprint(f\"Number of legitimate sons with incomplete parents: {len(incomplete_legit_parents)}\")\nprint(f\"Number of ilegitimate sons with incomplete parents: {len(incomplete_ilegit_parents)}\")\n\nNumber of legitimate sons with incomplete parents: 42\nNumber of ilegitimate sons with incomplete parents: 9\n\n\nThe results show excellent parental linkage quality:\n\nLegitimate personas (9,110 total): Only 0.46% (42 cases) have incomplete parental records\nIllegitimate personas (1,310 total): Only 0.68% (9 cases) lack at least one parent\n\nThis high completeness rate indicates that the extraction process successfully preserved family relationships recorded in the sacramental registers.\n\n\nTemporal Completeness\nWe assess the availability of birth and death dates, which are essential for temporal reasoning in record linkage.\n\nnobirthdate = personas.loc[personas['birth_date'].isna()]\npersonas_size = len(personas)\nnobirthdate_size = len(nobirthdate)\npercentage_nobirthdate = (nobirthdate_size / personas_size) * 100\nprint(f\"Percentage of personas with missing birth dates: {percentage_nobirthdate:.2f}%\")\nnobirthdate['persona_type'].value_counts()\n\nPercentage of personas with missing birth dates: 81.74%\n\n\npersona_type\nmother               7614\nfather               7369\nwitness              4249\ngodparent            3260\ngodmother            3251\ngodfather            3012\nwife                 1470\nmother_of_wife       1459\nhusband              1441\nmother_of_husband    1439\nfather_of_wife       1438\nfather_of_husband    1410\nbaptized              978\ndeceased               86\nName: count, dtype: int64\n\n\n\nnodeathdate = personas.loc[personas['death_date'].isna()]\nnodeathdate_size = len(nodeathdate)\npercentage_nodeathdate = (nodeathdate_size / personas_size) * 100\nprint(f\"Percentage of personas with missing death dates: {percentage_nodeathdate:.2f}%\")\nnodeathdate['persona_type'].value_counts()\n\nPercentage of personas with missing death dates: 95.51%\n\n\npersona_type\nmother               7614\nfather               7369\nbaptized             6340\nwitness              4249\ngodparent            3260\ngodmother            3251\ngodfather            3012\nwife                 2060\nhusband              2051\nmother_of_wife       1459\nmother_of_husband    1439\nfather_of_wife       1438\nfather_of_husband    1410\ndeceased                6\nName: count, dtype: int64\n\n\n\n\nSpatial Completeness\nBirth and death places provide geographic context for mobility analysis and help disambiguate between individuals with similar names.\n\nnonbirthplace = personas.loc[personas['birth_place'].isna()]\nnonbirthplace_size = len(nonbirthplace)\npercentage_nonbirthplace = (nonbirthplace_size / personas_size) * 100\nprint(f\"Percentage of personas with missing birth places: {percentage_nonbirthplace:.2f}%\")\nnonbirthplace['persona_type'].value_counts()\n\nPercentage of personas with missing birth places: 88.57%\n\n\npersona_type\nmother               7614\nfather               7369\nbaptized             4532\nwitness              4249\ngodparent            3260\ngodmother            3251\ngodfather            3012\nmother_of_wife       1459\nmother_of_husband    1439\nfather_of_wife       1438\nfather_of_husband    1410\nwife                 1154\nhusband              1114\ndeceased              393\nName: count, dtype: int64\n\n\n\nnodeathplace = personas.loc[personas['death_place'].isna()]\nnodeathplace_size = len(nodeathplace)\npercentage_nodeathplace = (nodeathplace_size / personas_size) * 100\nprint(f\"Percentage of personas with missing death places: {percentage_nodeathplace:.2f}%\")\nnodeathplace['persona_type'].value_counts()\n\nPercentage of personas with missing death places: 96.79%\n\n\npersona_type\nmother               7614\nfather               7369\nbaptized             6340\nwitness              4249\ngodparent            3260\ngodmother            3251\ngodfather            3012\nwife                 2060\nhusband              2051\nmother_of_wife       1459\nmother_of_husband    1439\nfather_of_wife       1438\nfather_of_husband    1410\ndeceased              607\nName: count, dtype: int64\n\n\n\n# personas with both birth and death places present\nbirth_and_death_places = personas.loc[personas['birth_place'].notna() & personas['death_place'].notna()]\nbirth_and_death_places_size = len(birth_and_death_places)\npercentage_birth_and_death_places = (birth_and_death_places_size / personas_size) * 100\nprint(f\"Percentage of personas with both birth and death places present: {percentage_birth_and_death_places:.2f}%\")\nbirth_and_death_places['persona_type'].value_counts()\n\nPercentage of personas with both birth and death places present: 2.59%\n\n\npersona_type\ndeceased    1219\nName: count, dtype: int64\n\n\n\n\nAttribute Completeness\nWe examine the completeness of harmonized social and legal status attributes (legitimacy, marital status, social condition), which provide contextual information that can strengthen or weaken linkage hypotheses.\n\nlegitimacy_missing = personas.loc[personas['legitimacy_status'].isna()]\nlegitimacy_missing_size = len(legitimacy_missing)\npercentage_legitimacy_missing = (legitimacy_missing_size / personas_size) * 100\nprint(f\"Percentage of personas with missing legitimacy status: {percentage_legitimacy_missing:.2f}%\")\nlegitimacy_missing['persona_type'].value_counts()\n\nPercentage of personas with missing legitimacy status: 74.79%\n\n\npersona_type\nmother               7608\nfather               7365\nwitness              4249\ngodparent            3258\ngodmother            3248\ngodfather            3008\nmother_of_wife       1113\nfather_of_wife       1093\nmother_of_husband    1085\nfather_of_husband    1058\ndeceased              813\nhusband               638\nwife                  623\nbaptized               47\nName: count, dtype: int64\n\n\n\nmarital_status_missing = personas.loc[personas['marital_status'].isna()]\nmarital_status_missing_size = len(marital_status_missing)\npercentage_marital_status_missing = (marital_status_missing_size / personas_size) * 100\nprint(f\"Percentage of personas with missing marital status: {percentage_marital_status_missing:.2f}%\")\nmarital_status_missing['persona_type'].value_counts()\n\nPercentage of personas with missing marital status: 90.92%\n\n\npersona_type\nmother               7550\nfather               7362\nbaptized             6340\nwitness              4249\ngodmother            3250\ngodparent            3241\ngodfather            3011\nmother_of_wife       1459\nmother_of_husband    1438\nfather_of_wife       1438\nfather_of_husband    1410\ndeceased              917\nwife                  586\nhusband               546\nName: count, dtype: int64\n\n\n\nsocial_condition_missing = personas.loc[personas['social_condition'].isna()]\nsocial_condition_missing_size = len(social_condition_missing)\npercentage_social_condition_missing = (social_condition_missing_size / personas_size) * 100\nprint(f\"Percentage of personas with missing social condition: {percentage_social_condition_missing:.2f}%\")\nsocial_condition_missing['persona_type'].value_counts()\n\nPercentage of personas with missing social condition: 79.51%\n\n\npersona_type\nmother               6715\nfather               6564\nbaptized             4338\nwitness              4249\ngodparent            2967\ngodfather            2922\ngodmother            2901\nwife                 1196\nhusband              1145\nmother_of_wife        955\nfather_of_wife        938\nmother_of_husband     938\nfather_of_husband     917\ndeceased              684\nName: count, dtype: int64\n\n\n\n\nAggregate Completeness Metrics\nBeyond individual field completeness, we calculate overall completeness scores to understand the general quality of persona records. We compute both a simple completeness score (proportion of non-null fields) and a weighted score that prioritizes critical fields for record linkage.\n\nSimple Completeness Score\nThe simple score treats all fields equally, providing a general measure of data richness.\n\npersonas['completeness_score'] = personas.notna().sum(axis=1) / len(personas.columns)\npersonas.groupby('persona_type')['completeness_score'].mean().sort_values(ascending=False)\n\npersona_type\ndeceased             0.821415\nhusband              0.656038\nwife                 0.651748\nbaptized             0.629243\nmother_of_husband    0.506092\nmother_of_wife       0.505186\nfather_of_husband    0.504492\nfather_of_wife       0.503755\nmother               0.474424\nfather               0.473651\ngodmother            0.473372\ngodparent            0.472822\ngodfather            0.468216\nwitness              0.466510\nName: completeness_score, dtype: float64\n\n\n\n\nWeighted Completeness Score\nThe weighted score assigns higher importance to fields crucial for record linkage (names, dates) and lower weights to supplementary attributes (social condition, residence). This reflects the differential utility of fields in matching algorithms.\n\nweights = {\n    'name': 0.15,\n    'lastname': 0.15,\n    'birth_date': 0.125,\n    'death_date': 0.125,\n    'birth_place': 0.10,\n    'death_place': 0.10,\n    'legitimacy_status': 0.05,\n    'marital_status': 0.05,\n    'social_condition': 0.05,\n    'gender': 0.05,\n    'resident_in': 0.05\n}\n\ndef weighted_completeness(row, weights):\n    score = 0.0\n    for col, w in weights.items():\n        if pd.notna(row[col]):\n            score += w\n    return score\n\npersonas['weighted_completeness'] = personas.apply(weighted_completeness, axis=1, weights=weights)\npersonas.groupby('persona_type')['weighted_completeness'].mean().sort_values(ascending=False)\n\npersona_type\ndeceased             0.836722\nbaptized             0.549558\nhusband              0.536738\nwife                 0.531650\nmother_of_husband    0.379222\nmother_of_wife       0.378410\nfather_of_husband    0.375177\nfather_of_wife       0.374687\nmother               0.354728\nfather               0.354641\ngodparent            0.354218\ngodmother            0.354199\ngodfather            0.350332\nwitness              0.349647\nName: weighted_completeness, dtype: float64\n\n\n\n\nComparison of Completeness Metrics\nVisualizing the relationship between simple and weighted completeness reveals how different persona types vary in their possession of high-priority fields.\n\n# plot correlation between completeness_score and weighted_completeness\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=personas, x='completeness_score', y='weighted_completeness', hue='persona_type')\nplt.title('Correlation between Completeness Score and Weighted Completeness')\nplt.xlabel('Completeness Score')\nplt.ylabel('Weighted Completeness')\nplt.legend(title='Persona Type', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Notebooks",
      "Personas Creation"
    ]
  },
  {
    "objectID": "4_personasCreation.html#summary-and-implications",
    "href": "4_personasCreation.html#summary-and-implications",
    "title": "Personas Creation",
    "section": "Summary and Implications",
    "text": "Summary and Implications\nThe quality assessment reveals that the persona extraction process successfully preserved historical information with high fidelity:\n\nName completeness is excellent for most persona types, with missing names concentrated in expected categories (e.g., godparents, witnesses)\nParental linkages are nearly complete (&gt;99%) for both legitimate and illegitimate children, enabling family reconstruction\nTemporal and spatial data show variable completeness depending on persona type, reflecting the original documentary practices\nWeighted completeness scores indicate that core linkage fields (names, dates) are well-populated across persona types\n\nThese results suggest that the dataset is well-suited for probabilistic record linkage, with sufficient information density to support robust matching algorithms while retaining the historical nuances present in the original sacramental registers.",
    "crumbs": [
      "Notebooks",
      "Personas Creation"
    ]
  }
]